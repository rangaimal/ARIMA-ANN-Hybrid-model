{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ASPI</th>\n",
       "      <th>Banks_finance_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>96.09</td>\n",
       "      <td>84.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985-01-03</td>\n",
       "      <td>96.08</td>\n",
       "      <td>85.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985-01-04</td>\n",
       "      <td>96.05</td>\n",
       "      <td>85.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>96.18</td>\n",
       "      <td>86.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985-01-08</td>\n",
       "      <td>96.34</td>\n",
       "      <td>87.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   ASPI  Banks_finance_insurance\n",
       "0 1985-01-02  96.09                    84.88\n",
       "1 1985-01-03  96.08                    85.07\n",
       "2 1985-01-04  96.05                    85.07\n",
       "3 1985-01-07  96.18                    86.82\n",
       "4 1985-01-08  96.34                    87.58"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel(r'C:/Users/Acer/Desktop/Research/Market indices DailyOneSector.xlsx', header =0)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date_year'] = dataset['Date'].dt.year\n",
    "dataset['date_month'] = dataset['Date'].dt.month\n",
    "dataset['date_day'] = dataset['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ASPI</th>\n",
       "      <th>Banks_finance_insurance</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>96.09</td>\n",
       "      <td>84.88</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985-01-03</td>\n",
       "      <td>96.08</td>\n",
       "      <td>85.07</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985-01-04</td>\n",
       "      <td>96.05</td>\n",
       "      <td>85.07</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>96.18</td>\n",
       "      <td>86.82</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985-01-08</td>\n",
       "      <td>96.34</td>\n",
       "      <td>87.58</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   ASPI  Banks_finance_insurance  date_year  date_month  date_day\n",
       "0 1985-01-02  96.09                    84.88       1985           1         2\n",
       "1 1985-01-03  96.08                    85.07       1985           1         3\n",
       "2 1985-01-04  96.05                    85.07       1985           1         4\n",
       "3 1985-01-07  96.18                    86.82       1985           1         7\n",
       "4 1985-01-08  96.34                    87.58       1985           1         8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASPI</th>\n",
       "      <th>Banks_finance_insurance</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.09</td>\n",
       "      <td>84.88</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.08</td>\n",
       "      <td>85.07</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.05</td>\n",
       "      <td>85.07</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.18</td>\n",
       "      <td>86.82</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.34</td>\n",
       "      <td>87.58</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>5974.94</td>\n",
       "      <td>14504.04</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>5985.08</td>\n",
       "      <td>14513.48</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>6021.54</td>\n",
       "      <td>14578.73</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>6040.18</td>\n",
       "      <td>14575.46</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>6061.94</td>\n",
       "      <td>14748.99</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7713 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASPI  Banks_finance_insurance  date_year  date_month  date_day\n",
       "0       96.09                    84.88       1985           1         2\n",
       "1       96.08                    85.07       1985           1         3\n",
       "2       96.05                    85.07       1985           1         4\n",
       "3       96.18                    86.82       1985           1         7\n",
       "4       96.34                    87.58       1985           1         8\n",
       "...       ...                      ...        ...         ...       ...\n",
       "7708  5974.94                 14504.04       2017           3        27\n",
       "7709  5985.08                 14513.48       2017           3        28\n",
       "7710  6021.54                 14578.73       2017           3        29\n",
       "7711  6040.18                 14575.46       2017           3        30\n",
       "7712  6061.94                 14748.99       2017           3        31\n",
       "\n",
       "[7713 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['ASPI','Banks_finance_insurance','date_year','date_month','date_day']]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   84.88]\n",
      " [   85.07]\n",
      " [   85.07]\n",
      " ...\n",
      " [14578.73]\n",
      " [14575.46]\n",
      " [14748.99]]\n",
      "[1985 1985 1985 ... 2017 2017 2017]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 1:2].values\n",
    "y = dataset.iloc[:, 2].values\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5399, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5399,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1, units=9, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=9, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5399 samples, validate on 2314 samples\n",
      "Epoch 1/100\n",
      "5399/5399 [==============================] - 2s 306us/step - loss: 1971.9501 - mean_absolute_error: 1971.9500 - mse: 3889677.2500 - val_loss: 1888.9887 - val_mean_absolute_error: 1888.9890 - val_mse: 3568366.5000\n",
      "Epoch 2/100\n",
      "5399/5399 [==============================] - 1s 270us/step - loss: 1611.4523 - mean_absolute_error: 1611.4519 - mse: 2636511.7500 - val_loss: 1200.1236 - val_mean_absolute_error: 1200.1237 - val_mse: 1440382.0000\n",
      "Epoch 3/100\n",
      "5399/5399 [==============================] - 1s 238us/step - loss: 521.7525 - mean_absolute_error: 521.7520 - mse: 436875.8750 - val_loss: 4.6572 - val_mean_absolute_error: 4.6572 - val_mse: 28.1387\n",
      "Epoch 4/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 4.7763 - mean_absolute_error: 4.7763 - mse: 30.8549 - val_loss: 4.7271 - val_mean_absolute_error: 4.7272 - val_mse: 29.8905\n",
      "Epoch 5/100\n",
      "5399/5399 [==============================] - 1s 243us/step - loss: 4.7978 - mean_absolute_error: 4.7978 - mse: 31.3599 - val_loss: 4.6593 - val_mean_absolute_error: 4.6593 - val_mse: 27.9686\n",
      "Epoch 6/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 4.7450 - mean_absolute_error: 4.7450 - mse: 30.2311 - val_loss: 4.9480 - val_mean_absolute_error: 4.9480 - val_mse: 33.4481\n",
      "Epoch 7/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 4.7803 - mean_absolute_error: 4.7803 - mse: 31.0635 - val_loss: 4.7315 - val_mean_absolute_error: 4.7315 - val_mse: 29.0298\n",
      "Epoch 8/100\n",
      "5399/5399 [==============================] - 1s 249us/step - loss: 4.7573 - mean_absolute_error: 4.7573 - mse: 30.7606 - val_loss: 4.8747 - val_mean_absolute_error: 4.8747 - val_mse: 35.7554\n",
      "Epoch 9/100\n",
      "5399/5399 [==============================] - 1s 259us/step - loss: 4.7692 - mean_absolute_error: 4.7692 - mse: 30.8821 - val_loss: 4.8165 - val_mean_absolute_error: 4.8165 - val_mse: 32.8714\n",
      "Epoch 10/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 4.7783 - mean_absolute_error: 4.7783 - mse: 30.9134 - val_loss: 4.7651 - val_mean_absolute_error: 4.7651 - val_mse: 29.5735\n",
      "Epoch 11/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.7693 - mean_absolute_error: 4.7693 - mse: 30.6522 - val_loss: 4.8401 - val_mean_absolute_error: 4.8401 - val_mse: 29.8929\n",
      "Epoch 12/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 4.8416 - mean_absolute_error: 4.8416 - mse: 31.7205 - val_loss: 4.9359 - val_mean_absolute_error: 4.9359 - val_mse: 34.8975\n",
      "Epoch 13/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 4.7981 - mean_absolute_error: 4.7981 - mse: 31.1398 - val_loss: 4.7820 - val_mean_absolute_error: 4.7820 - val_mse: 29.5921\n",
      "Epoch 14/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 4.8179 - mean_absolute_error: 4.8179 - mse: 31.3783 - val_loss: 5.1840 - val_mean_absolute_error: 5.1840 - val_mse: 38.6699\n",
      "Epoch 15/100\n",
      "5399/5399 [==============================] - 1s 242us/step - loss: 4.7722 - mean_absolute_error: 4.7722 - mse: 30.4674 - val_loss: 4.6935 - val_mean_absolute_error: 4.6935 - val_mse: 28.9263\n",
      "Epoch 16/100\n",
      "5399/5399 [==============================] - 2s 284us/step - loss: 4.7987 - mean_absolute_error: 4.7987 - mse: 31.2043 - val_loss: 4.8267 - val_mean_absolute_error: 4.8267 - val_mse: 29.8967\n",
      "Epoch 17/100\n",
      "5399/5399 [==============================] - 2s 292us/step - loss: 4.8663 - mean_absolute_error: 4.8663 - mse: 32.0117 - val_loss: 4.8959 - val_mean_absolute_error: 4.8959 - val_mse: 31.7067\n",
      "Epoch 18/100\n",
      "5399/5399 [==============================] - 1s 260us/step - loss: 4.7765 - mean_absolute_error: 4.7765 - mse: 30.6442 - val_loss: 4.9866 - val_mean_absolute_error: 4.9866 - val_mse: 36.1890\n",
      "Epoch 19/100\n",
      "5399/5399 [==============================] - 1s 242us/step - loss: 4.7324 - mean_absolute_error: 4.7324 - mse: 30.3807 - val_loss: 4.6559 - val_mean_absolute_error: 4.6559 - val_mse: 27.9605\n",
      "Epoch 20/100\n",
      "5399/5399 [==============================] - 2s 287us/step - loss: 4.7413 - mean_absolute_error: 4.7413 - mse: 30.5846 - val_loss: 4.7666 - val_mean_absolute_error: 4.7666 - val_mse: 30.4489\n",
      "Epoch 21/100\n",
      "5399/5399 [==============================] - 1s 277us/step - loss: 4.7891 - mean_absolute_error: 4.7891 - mse: 31.1005 - val_loss: 5.2124 - val_mean_absolute_error: 5.2124 - val_mse: 34.4123\n",
      "Epoch 22/100\n",
      "5399/5399 [==============================] - 2s 305us/step - loss: 4.7706 - mean_absolute_error: 4.7706 - mse: 31.2965 - val_loss: 4.8114 - val_mean_absolute_error: 4.8114 - val_mse: 32.7463\n",
      "Epoch 23/100\n",
      "5399/5399 [==============================] - 1s 254us/step - loss: 4.7929 - mean_absolute_error: 4.7929 - mse: 31.9417 - val_loss: 4.9568 - val_mean_absolute_error: 4.9568 - val_mse: 34.4698\n",
      "Epoch 24/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.7783 - mean_absolute_error: 4.7783 - mse: 31.5411 - val_loss: 4.6636 - val_mean_absolute_error: 4.6636 - val_mse: 28.2778\n",
      "Epoch 25/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 4.7572 - mean_absolute_error: 4.7572 - mse: 29.6405 - val_loss: 4.7329 - val_mean_absolute_error: 4.7329 - val_mse: 29.9803\n",
      "Epoch 26/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 4.7666 - mean_absolute_error: 4.7666 - mse: 30.4467 - val_loss: 4.6673 - val_mean_absolute_error: 4.6673 - val_mse: 28.5618\n",
      "Epoch 27/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.8372 - mean_absolute_error: 4.8372 - mse: 31.6691 - val_loss: 4.7056 - val_mean_absolute_error: 4.7056 - val_mse: 29.5811\n",
      "Epoch 28/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 4.8055 - mean_absolute_error: 4.8055 - mse: 31.0475 - val_loss: 4.9667 - val_mean_absolute_error: 4.9667 - val_mse: 36.4332\n",
      "Epoch 29/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 4.8011 - mean_absolute_error: 4.8011 - mse: 31.8494 - val_loss: 5.1512 - val_mean_absolute_error: 5.1512 - val_mse: 39.3059\n",
      "Epoch 30/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.8286 - mean_absolute_error: 4.8286 - mse: 31.2908 - val_loss: 4.7741 - val_mean_absolute_error: 4.7741 - val_mse: 29.2852\n",
      "Epoch 31/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 4.7639 - mean_absolute_error: 4.7639 - mse: 30.6596 - val_loss: 4.6484 - val_mean_absolute_error: 4.6484 - val_mse: 28.0051\n",
      "Epoch 32/100\n",
      "5399/5399 [==============================] - 1s 257us/step - loss: 4.7747 - mean_absolute_error: 4.7747 - mse: 31.4097 - val_loss: 5.2408 - val_mean_absolute_error: 5.2408 - val_mse: 37.9386\n",
      "Epoch 33/100\n",
      "5399/5399 [==============================] - 1s 250us/step - loss: 4.8015 - mean_absolute_error: 4.8015 - mse: 30.7875 - val_loss: 6.5787 - val_mean_absolute_error: 6.5787 - val_mse: 67.5662\n",
      "Epoch 34/100\n",
      "5399/5399 [==============================] - 1s 243us/step - loss: 4.8046 - mean_absolute_error: 4.8046 - mse: 30.7384 - val_loss: 4.9467 - val_mean_absolute_error: 4.9467 - val_mse: 31.3840\n",
      "Epoch 35/100\n",
      "5399/5399 [==============================] - 2s 283us/step - loss: 4.7670 - mean_absolute_error: 4.7670 - mse: 30.6631 - val_loss: 5.0366 - val_mean_absolute_error: 5.0366 - val_mse: 32.9393\n",
      "Epoch 36/100\n",
      "5399/5399 [==============================] - 1s 275us/step - loss: 4.8087 - mean_absolute_error: 4.8087 - mse: 31.4418 - val_loss: 4.6542 - val_mean_absolute_error: 4.6542 - val_mse: 28.2150\n",
      "Epoch 37/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 4.7378 - mean_absolute_error: 4.7378 - mse: 30.8219 - val_loss: 4.9168 - val_mean_absolute_error: 4.9168 - val_mse: 34.3660\n",
      "Epoch 38/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 4.7860 - mean_absolute_error: 4.7860 - mse: 31.0570 - val_loss: 4.7039 - val_mean_absolute_error: 4.7039 - val_mse: 29.5347\n",
      "Epoch 39/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 4.7771 - mean_absolute_error: 4.7771 - mse: 31.1309 - val_loss: 4.7287 - val_mean_absolute_error: 4.7287 - val_mse: 29.9096\n",
      "Epoch 40/100\n",
      "5399/5399 [==============================] - 1s 245us/step - loss: 4.7867 - mean_absolute_error: 4.7867 - mse: 31.0426 - val_loss: 4.9735 - val_mean_absolute_error: 4.9735 - val_mse: 31.7114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "5399/5399 [==============================] - 1s 243us/step - loss: 4.7031 - mean_absolute_error: 4.7031 - mse: 29.7659 - val_loss: 4.7055 - val_mean_absolute_error: 4.7055 - val_mse: 28.6428\n",
      "Epoch 42/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 4.7767 - mean_absolute_error: 4.7767 - mse: 30.9520 - val_loss: 4.9231 - val_mean_absolute_error: 4.9231 - val_mse: 35.3792\n",
      "Epoch 43/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.7466 - mean_absolute_error: 4.7466 - mse: 30.6364 - val_loss: 4.9305 - val_mean_absolute_error: 4.9305 - val_mse: 31.5438\n",
      "Epoch 44/100\n",
      "5399/5399 [==============================] - 1s 250us/step - loss: 4.7090 - mean_absolute_error: 4.7090 - mse: 30.1768 - val_loss: 5.7166 - val_mean_absolute_error: 5.7166 - val_mse: 53.6844\n",
      "Epoch 45/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 4.7795 - mean_absolute_error: 4.7795 - mse: 31.4735 - val_loss: 4.8665 - val_mean_absolute_error: 4.8665 - val_mse: 34.3925\n",
      "Epoch 46/100\n",
      "5399/5399 [==============================] - 1s 239us/step - loss: 4.7703 - mean_absolute_error: 4.7703 - mse: 30.3108 - val_loss: 4.8103 - val_mean_absolute_error: 4.8103 - val_mse: 30.0952\n",
      "Epoch 47/100\n",
      "5399/5399 [==============================] - 1s 228us/step - loss: 4.7738 - mean_absolute_error: 4.7738 - mse: 31.4064 - val_loss: 4.6718 - val_mean_absolute_error: 4.6718 - val_mse: 28.3775\n",
      "Epoch 48/100\n",
      "5399/5399 [==============================] - 1s 227us/step - loss: 4.8064 - mean_absolute_error: 4.8064 - mse: 31.6433 - val_loss: 4.7101 - val_mean_absolute_error: 4.7101 - val_mse: 29.5401\n",
      "Epoch 49/100\n",
      "5399/5399 [==============================] - 1s 225us/step - loss: 4.7473 - mean_absolute_error: 4.7473 - mse: 30.6123 - val_loss: 4.6774 - val_mean_absolute_error: 4.6774 - val_mse: 28.6874\n",
      "Epoch 50/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 4.7870 - mean_absolute_error: 4.7870 - mse: 31.0270 - val_loss: 4.6853 - val_mean_absolute_error: 4.6853 - val_mse: 28.5359\n",
      "Epoch 51/100\n",
      "5399/5399 [==============================] - 1s 275us/step - loss: 4.8051 - mean_absolute_error: 4.8051 - mse: 31.2479 - val_loss: 4.8316 - val_mean_absolute_error: 4.8316 - val_mse: 34.0421\n",
      "Epoch 52/100\n",
      "5399/5399 [==============================] - 1s 228us/step - loss: 4.7643 - mean_absolute_error: 4.7643 - mse: 30.4781 - val_loss: 5.0577 - val_mean_absolute_error: 5.0578 - val_mse: 32.2962\n",
      "Epoch 53/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 4.7904 - mean_absolute_error: 4.7904 - mse: 30.4823 - val_loss: 4.6710 - val_mean_absolute_error: 4.6710 - val_mse: 28.6582\n",
      "Epoch 54/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 4.8499 - mean_absolute_error: 4.8499 - mse: 31.7991 - val_loss: 5.0596 - val_mean_absolute_error: 5.0596 - val_mse: 36.8055\n",
      "Epoch 55/100\n",
      "5399/5399 [==============================] - 1s 226us/step - loss: 4.8048 - mean_absolute_error: 4.8048 - mse: 31.3547 - val_loss: 4.7530 - val_mean_absolute_error: 4.7530 - val_mse: 30.9726\n",
      "Epoch 56/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 4.7979 - mean_absolute_error: 4.7979 - mse: 31.0356 - val_loss: 4.9726 - val_mean_absolute_error: 4.9726 - val_mse: 36.4060\n",
      "Epoch 57/100\n",
      "5399/5399 [==============================] - 1s 257us/step - loss: 4.8226 - mean_absolute_error: 4.8226 - mse: 31.0002 - val_loss: 4.6549 - val_mean_absolute_error: 4.6549 - val_mse: 28.1153\n",
      "Epoch 58/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.7662 - mean_absolute_error: 4.7662 - mse: 30.8903 - val_loss: 5.2627 - val_mean_absolute_error: 5.2627 - val_mse: 41.2009\n",
      "Epoch 59/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 4.8212 - mean_absolute_error: 4.8212 - mse: 32.0100 - val_loss: 4.9880 - val_mean_absolute_error: 4.9880 - val_mse: 34.9204\n",
      "Epoch 60/100\n",
      "5399/5399 [==============================] - 1s 243us/step - loss: 4.8108 - mean_absolute_error: 4.8108 - mse: 30.8208 - val_loss: 4.6512 - val_mean_absolute_error: 4.6512 - val_mse: 27.9364\n",
      "Epoch 61/100\n",
      "5399/5399 [==============================] - 1s 246us/step - loss: 4.7806 - mean_absolute_error: 4.7806 - mse: 31.0841 - val_loss: 4.6510 - val_mean_absolute_error: 4.6510 - val_mse: 28.1309\n",
      "Epoch 62/100\n",
      "5399/5399 [==============================] - 1s 250us/step - loss: 4.7645 - mean_absolute_error: 4.7645 - mse: 30.5422 - val_loss: 4.8279 - val_mean_absolute_error: 4.8279 - val_mse: 30.1993\n",
      "Epoch 63/100\n",
      "5399/5399 [==============================] - 1s 248us/step - loss: 4.7612 - mean_absolute_error: 4.7612 - mse: 30.3317 - val_loss: 4.9355 - val_mean_absolute_error: 4.9355 - val_mse: 33.3219\n",
      "Epoch 64/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 4.7862 - mean_absolute_error: 4.7862 - mse: 30.4752 - val_loss: 5.1906 - val_mean_absolute_error: 5.1906 - val_mse: 43.9763\n",
      "Epoch 65/100\n",
      "5399/5399 [==============================] - 2s 284us/step - loss: 4.7779 - mean_absolute_error: 4.7779 - mse: 30.9723 - val_loss: 4.7593 - val_mean_absolute_error: 4.7593 - val_mse: 29.2050\n",
      "Epoch 66/100\n",
      "5399/5399 [==============================] - 2s 353us/step - loss: 4.8438 - mean_absolute_error: 4.8438 - mse: 31.8004 - val_loss: 4.7209 - val_mean_absolute_error: 4.7209 - val_mse: 29.1648\n",
      "Epoch 67/100\n",
      "5399/5399 [==============================] - 2s 316us/step - loss: 4.7869 - mean_absolute_error: 4.7869 - mse: 30.8330 - val_loss: 4.7368 - val_mean_absolute_error: 4.7368 - val_mse: 29.4298\n",
      "Epoch 68/100\n",
      "5399/5399 [==============================] - 2s 292us/step - loss: 4.7838 - mean_absolute_error: 4.7838 - mse: 31.0053 - val_loss: 4.9540 - val_mean_absolute_error: 4.9540 - val_mse: 32.5164\n",
      "Epoch 69/100\n",
      "5399/5399 [==============================] - 1s 259us/step - loss: 4.8126 - mean_absolute_error: 4.8126 - mse: 31.9973 - val_loss: 5.2200 - val_mean_absolute_error: 5.2200 - val_mse: 44.8256\n",
      "Epoch 70/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 4.7662 - mean_absolute_error: 4.7662 - mse: 30.5123 - val_loss: 4.7118 - val_mean_absolute_error: 4.7118 - val_mse: 29.3476\n",
      "Epoch 71/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 4.8147 - mean_absolute_error: 4.8147 - mse: 31.5827 - val_loss: 4.8414 - val_mean_absolute_error: 4.8414 - val_mse: 30.1735\n",
      "Epoch 72/100\n",
      "5399/5399 [==============================] - 1s 238us/step - loss: 4.7677 - mean_absolute_error: 4.7677 - mse: 30.8481 - val_loss: 5.4701 - val_mean_absolute_error: 5.4701 - val_mse: 41.9551\n",
      "Epoch 73/100\n",
      "5399/5399 [==============================] - 1s 241us/step - loss: 4.8767 - mean_absolute_error: 4.8767 - mse: 33.5206 - val_loss: 4.7748 - val_mean_absolute_error: 4.7748 - val_mse: 31.1711\n",
      "Epoch 74/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.7327 - mean_absolute_error: 4.7327 - mse: 30.8249 - val_loss: 5.4488 - val_mean_absolute_error: 5.4488 - val_mse: 41.1496\n",
      "Epoch 75/100\n",
      "5399/5399 [==============================] - 1s 243us/step - loss: 4.8521 - mean_absolute_error: 4.8521 - mse: 31.8238 - val_loss: 4.6992 - val_mean_absolute_error: 4.6992 - val_mse: 28.8097\n",
      "Epoch 76/100\n",
      "5399/5399 [==============================] - 2s 281us/step - loss: 4.8044 - mean_absolute_error: 4.8045 - mse: 31.7000 - val_loss: 4.7582 - val_mean_absolute_error: 4.7582 - val_mse: 29.5820\n",
      "Epoch 77/100\n",
      "5399/5399 [==============================] - 1s 259us/step - loss: 4.7263 - mean_absolute_error: 4.7263 - mse: 29.8717 - val_loss: 5.1424 - val_mean_absolute_error: 5.1424 - val_mse: 36.2388\n",
      "Epoch 78/100\n",
      "5399/5399 [==============================] - 1s 241us/step - loss: 4.7688 - mean_absolute_error: 4.7688 - mse: 30.2738 - val_loss: 4.7127 - val_mean_absolute_error: 4.7127 - val_mse: 28.7417\n",
      "Epoch 79/100\n",
      "5399/5399 [==============================] - 2s 308us/step - loss: 4.7660 - mean_absolute_error: 4.7660 - mse: 31.5716 - val_loss: 4.9908 - val_mean_absolute_error: 4.9908 - val_mse: 32.8438\n",
      "Epoch 80/100\n",
      "5399/5399 [==============================] - 2s 305us/step - loss: 4.7280 - mean_absolute_error: 4.7280 - mse: 29.9431 - val_loss: 5.1559 - val_mean_absolute_error: 5.1559 - val_mse: 38.8027\n",
      "Epoch 81/100\n",
      "5399/5399 [==============================] - 1s 265us/step - loss: 4.7948 - mean_absolute_error: 4.7948 - mse: 31.4685 - val_loss: 4.8137 - val_mean_absolute_error: 4.8137 - val_mse: 30.0594\n",
      "Epoch 82/100\n",
      "5399/5399 [==============================] - 1s 257us/step - loss: 4.8258 - mean_absolute_error: 4.8258 - mse: 31.7404 - val_loss: 5.1104 - val_mean_absolute_error: 5.1104 - val_mse: 33.3437\n",
      "Epoch 83/100\n",
      "5399/5399 [==============================] - 2s 293us/step - loss: 4.7405 - mean_absolute_error: 4.7405 - mse: 30.3645 - val_loss: 4.8974 - val_mean_absolute_error: 4.8974 - val_mse: 31.8716\n",
      "Epoch 84/100\n",
      "5399/5399 [==============================] - 2s 310us/step - loss: 4.8147 - mean_absolute_error: 4.8147 - mse: 31.5100 - val_loss: 4.8807 - val_mean_absolute_error: 4.8807 - val_mse: 31.6930\n",
      "Epoch 85/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.7883 - mean_absolute_error: 4.7883 - mse: 30.6751 - val_loss: 4.9035 - val_mean_absolute_error: 4.9035 - val_mse: 31.7041\n",
      "Epoch 86/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 4.7884 - mean_absolute_error: 4.7884 - mse: 31.3502 - val_loss: 4.9091 - val_mean_absolute_error: 4.9091 - val_mse: 33.3644\n",
      "Epoch 87/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 4.7674 - mean_absolute_error: 4.7674 - mse: 31.1994 - val_loss: 4.8293 - val_mean_absolute_error: 4.8293 - val_mse: 33.0498\n",
      "Epoch 88/100\n",
      "5399/5399 [==============================] - 1s 253us/step - loss: 4.7407 - mean_absolute_error: 4.7407 - mse: 30.2502 - val_loss: 4.8732 - val_mean_absolute_error: 4.8732 - val_mse: 32.5990\n",
      "Epoch 89/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 4.7571 - mean_absolute_error: 4.7571 - mse: 31.0806 - val_loss: 4.9646 - val_mean_absolute_error: 4.9646 - val_mse: 36.5638\n",
      "Epoch 90/100\n",
      "5399/5399 [==============================] - 1s 258us/step - loss: 4.7649 - mean_absolute_error: 4.7649 - mse: 30.6372 - val_loss: 5.0676 - val_mean_absolute_error: 5.0676 - val_mse: 33.2051\n",
      "Epoch 91/100\n",
      "5399/5399 [==============================] - 1s 256us/step - loss: 4.8156 - mean_absolute_error: 4.8156 - mse: 31.1110 - val_loss: 4.7069 - val_mean_absolute_error: 4.7069 - val_mse: 29.6055\n",
      "Epoch 92/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 4.7557 - mean_absolute_error: 4.7557 - mse: 30.3298 - val_loss: 5.1719 - val_mean_absolute_error: 5.1719 - val_mse: 33.8320\n",
      "Epoch 93/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 4.7407 - mean_absolute_error: 4.7407 - mse: 30.2438 - val_loss: 4.9586 - val_mean_absolute_error: 4.9586 - val_mse: 31.9810\n",
      "Epoch 94/100\n",
      "5399/5399 [==============================] - 1s 239us/step - loss: 4.7794 - mean_absolute_error: 4.7794 - mse: 31.3762 - val_loss: 4.6848 - val_mean_absolute_error: 4.6848 - val_mse: 28.4933\n",
      "Epoch 95/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 4.8305 - mean_absolute_error: 4.8305 - mse: 31.6521 - val_loss: 4.8392 - val_mean_absolute_error: 4.8392 - val_mse: 30.1174\n",
      "Epoch 96/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 4.8152 - mean_absolute_error: 4.8152 - mse: 31.7086 - val_loss: 5.2285 - val_mean_absolute_error: 5.2285 - val_mse: 38.8338\n",
      "Epoch 97/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 4.7899 - mean_absolute_error: 4.7899 - mse: 30.7277 - val_loss: 4.7123 - val_mean_absolute_error: 4.7123 - val_mse: 29.1110\n",
      "Epoch 98/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 4.7609 - mean_absolute_error: 4.7609 - mse: 30.5283 - val_loss: 5.2882 - val_mean_absolute_error: 5.2882 - val_mse: 48.8880\n",
      "Epoch 99/100\n",
      "5399/5399 [==============================] - 1s 238us/step - loss: 4.7681 - mean_absolute_error: 4.7681 - mse: 31.4562 - val_loss: 4.9190 - val_mean_absolute_error: 4.9190 - val_mse: 31.1011\n",
      "Epoch 100/100\n",
      "5399/5399 [==============================] - 1s 247us/step - loss: 4.8357 - mean_absolute_error: 4.8357 - mse: 31.9240 - val_loss: 5.0080 - val_mean_absolute_error: 5.0080 - val_mse: 33.4712\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform',  input_dim = 1))\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform'))\n",
    "classifier.add(Dense(1))\n",
    "classifier.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error','mse'])\n",
    "history=classifier.fit(X_train, y_train,validation_data =[X_test,y_test], batch_size = 10, nb_epoch = 100)\n",
    "classifier.save('stock_prediction4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model('stock_prediction4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2314/2314 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.007975928620624"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE,mse,loss = classifier.evaluate(X_test,y_test)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1, units=9, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=9, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5399 samples, validate on 2314 samples\n",
      "Epoch 1/100\n",
      "5399/5399 [==============================] - 1s 276us/step - loss: 98.4762 - mape: 98.4762 - val_loss: 94.1748 - val_mape: 94.1748\n",
      "Epoch 2/100\n",
      "5399/5399 [==============================] - 1s 268us/step - loss: 80.0746 - mape: 80.0746 - val_loss: 59.2647 - val_mape: 59.2648\n",
      "Epoch 3/100\n",
      "5399/5399 [==============================] - 1s 254us/step - loss: 25.3224 - mape: 25.3224 - val_loss: 0.2435 - val_mape: 0.2435\n",
      "Epoch 4/100\n",
      "5399/5399 [==============================] - 1s 247us/step - loss: 0.2384 - mape: 0.2384 - val_loss: 0.2447 - val_mape: 0.2447\n",
      "Epoch 5/100\n",
      "5399/5399 [==============================] - 1s 241us/step - loss: 0.2400 - mape: 0.2400 - val_loss: 0.2363 - val_mape: 0.2363\n",
      "Epoch 6/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2376 - mape: 0.2376 - val_loss: 0.2361 - val_mape: 0.2361\n",
      "Epoch 7/100\n",
      "5399/5399 [==============================] - 1s 227us/step - loss: 0.2395 - mape: 0.2395 - val_loss: 0.2325 - val_mape: 0.2325\n",
      "Epoch 8/100\n",
      "5399/5399 [==============================] - 1s 238us/step - loss: 0.2374 - mape: 0.2374 - val_loss: 0.2428 - val_mape: 0.2428\n",
      "Epoch 9/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2388 - mape: 0.2388 - val_loss: 0.2396 - val_mape: 0.2396\n",
      "Epoch 10/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2387 - mape: 0.2387 - val_loss: 0.2474 - val_mape: 0.2474\n",
      "Epoch 11/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 0.2399 - mape: 0.2399 - val_loss: 0.2362 - val_mape: 0.2362\n",
      "Epoch 12/100\n",
      "5399/5399 [==============================] - 1s 246us/step - loss: 0.2388 - mape: 0.2388 - val_loss: 0.2327 - val_mape: 0.2327\n",
      "Epoch 13/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2424 - mape: 0.2424 - val_loss: 0.2345 - val_mape: 0.2345\n",
      "Epoch 14/100\n",
      "5399/5399 [==============================] - 1s 238us/step - loss: 0.2374 - mape: 0.2374 - val_loss: 0.2411 - val_mape: 0.2411\n",
      "Epoch 15/100\n",
      "5399/5399 [==============================] - 1s 270us/step - loss: 0.2369 - mape: 0.2369 - val_loss: 0.2326 - val_mape: 0.2326\n",
      "Epoch 16/100\n",
      "5399/5399 [==============================] - 1s 272us/step - loss: 0.2408 - mape: 0.2408 - val_loss: 0.2524 - val_mape: 0.2524\n",
      "Epoch 17/100\n",
      "5399/5399 [==============================] - 1s 264us/step - loss: 0.2392 - mape: 0.2392 - val_loss: 0.2364 - val_mape: 0.2364\n",
      "Epoch 18/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 0.2414 - mape: 0.2414 - val_loss: 0.2700 - val_mape: 0.2700\n",
      "Epoch 19/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 0.2416 - mape: 0.2416 - val_loss: 0.2671 - val_mape: 0.2671\n",
      "Epoch 20/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2401 - mape: 0.2401 - val_loss: 0.2397 - val_mape: 0.2397\n",
      "Epoch 21/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2373 - mape: 0.2373 - val_loss: 0.2551 - val_mape: 0.2551\n",
      "Epoch 22/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2389 - mape: 0.2389 - val_loss: 0.2366 - val_mape: 0.2366\n",
      "Epoch 23/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 0.2395 - mape: 0.2395 - val_loss: 0.2624 - val_mape: 0.2624\n",
      "Epoch 24/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2393 - mape: 0.2393 - val_loss: 0.2354 - val_mape: 0.2354\n",
      "Epoch 25/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 0.2389 - mape: 0.2389 - val_loss: 0.2399 - val_mape: 0.2399\n",
      "Epoch 26/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2386 - mape: 0.2386 - val_loss: 0.2366 - val_mape: 0.2366\n",
      "Epoch 27/100\n",
      "5399/5399 [==============================] - 1s 261us/step - loss: 0.2389 - mape: 0.2389 - val_loss: 0.2342 - val_mape: 0.2342\n",
      "Epoch 28/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 0.2387 - mape: 0.2387 - val_loss: 0.2407 - val_mape: 0.2407\n",
      "Epoch 29/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2400 - mape: 0.2400 - val_loss: 0.2370 - val_mape: 0.2370\n",
      "Epoch 30/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 0.2407 - mape: 0.2407 - val_loss: 0.2351 - val_mape: 0.2351\n",
      "Epoch 31/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 0.2418 - mape: 0.2418 - val_loss: 0.2377 - val_mape: 0.2377\n",
      "Epoch 32/100\n",
      "5399/5399 [==============================] - 1s 230us/step - loss: 0.2434 - mape: 0.2434 - val_loss: 0.2379 - val_mape: 0.2379\n",
      "Epoch 33/100\n",
      "5399/5399 [==============================] - 1s 230us/step - loss: 0.2374 - mape: 0.2374 - val_loss: 0.2344 - val_mape: 0.2344\n",
      "Epoch 34/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 0.2399 - mape: 0.2399 - val_loss: 0.2393 - val_mape: 0.2393\n",
      "Epoch 35/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 0.2403 - mape: 0.2403 - val_loss: 0.2406 - val_mape: 0.2406\n",
      "Epoch 36/100\n",
      "5399/5399 [==============================] - 1s 228us/step - loss: 0.2398 - mape: 0.2398 - val_loss: 0.2337 - val_mape: 0.2337\n",
      "Epoch 37/100\n",
      "5399/5399 [==============================] - 1s 230us/step - loss: 0.2407 - mape: 0.2407 - val_loss: 0.2801 - val_mape: 0.2801\n",
      "Epoch 38/100\n",
      "5399/5399 [==============================] - 1s 230us/step - loss: 0.2410 - mape: 0.2410 - val_loss: 0.2385 - val_mape: 0.2385\n",
      "Epoch 39/100\n",
      "5399/5399 [==============================] - 1s 246us/step - loss: 0.2391 - mape: 0.2391 - val_loss: 0.2426 - val_mape: 0.2426\n",
      "Epoch 40/100\n",
      "5399/5399 [==============================] - 1s 257us/step - loss: 0.2375 - mape: 0.2375 - val_loss: 0.2374 - val_mape: 0.2374\n",
      "Epoch 41/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2405 - mape: 0.2405 - val_loss: 0.2445 - val_mape: 0.2445\n",
      "Epoch 42/100\n",
      "5399/5399 [==============================] - 1s 230us/step - loss: 0.2382 - mape: 0.2382 - val_loss: 0.2455 - val_mape: 0.2455\n",
      "Epoch 43/100\n",
      "5399/5399 [==============================] - 1s 243us/step - loss: 0.2402 - mape: 0.2402 - val_loss: 0.2483 - val_mape: 0.2483\n",
      "Epoch 44/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2397 - mape: 0.2397 - val_loss: 0.2537 - val_mape: 0.2537\n",
      "Epoch 45/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 0.2421 - mape: 0.2421 - val_loss: 0.2361 - val_mape: 0.2361\n",
      "Epoch 46/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2418 - mape: 0.2418 - val_loss: 0.2632 - val_mape: 0.2632\n",
      "Epoch 47/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 0.2395 - mape: 0.2395 - val_loss: 0.2330 - val_mape: 0.2330\n",
      "Epoch 48/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2391 - mape: 0.2391 - val_loss: 0.2400 - val_mape: 0.2400\n",
      "Epoch 49/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 0.2385 - mape: 0.2385 - val_loss: 0.2442 - val_mape: 0.2442\n",
      "Epoch 50/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2386 - mape: 0.2386 - val_loss: 0.2361 - val_mape: 0.2361\n",
      "Epoch 51/100\n",
      "5399/5399 [==============================] - 1s 252us/step - loss: 0.2375 - mape: 0.2375 - val_loss: 0.2451 - val_mape: 0.2451\n",
      "Epoch 52/100\n",
      "5399/5399 [==============================] - 1s 265us/step - loss: 0.2419 - mape: 0.2419 - val_loss: 0.2440 - val_mape: 0.2440\n",
      "Epoch 53/100\n",
      "5399/5399 [==============================] - 2s 306us/step - loss: 0.2398 - mape: 0.2398 - val_loss: 0.2514 - val_mape: 0.2514\n",
      "Epoch 54/100\n",
      "5399/5399 [==============================] - 1s 267us/step - loss: 0.2376 - mape: 0.2376 - val_loss: 0.2497 - val_mape: 0.2497\n",
      "Epoch 55/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2408 - mape: 0.2408 - val_loss: 0.2464 - val_mape: 0.2464\n",
      "Epoch 56/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 0.2389 - mape: 0.2389 - val_loss: 0.2409 - val_mape: 0.2409\n",
      "Epoch 57/100\n",
      "5399/5399 [==============================] - 1s 238us/step - loss: 0.2373 - mape: 0.2373 - val_loss: 0.2392 - val_mape: 0.2392\n",
      "Epoch 58/100\n",
      "5399/5399 [==============================] - 1s 248us/step - loss: 0.2378 - mape: 0.2378 - val_loss: 0.2496 - val_mape: 0.2496\n",
      "Epoch 59/100\n",
      "5399/5399 [==============================] - 1s 229us/step - loss: 0.2379 - mape: 0.2379 - val_loss: 0.2930 - val_mape: 0.2930\n",
      "Epoch 60/100\n",
      "5399/5399 [==============================] - 1s 245us/step - loss: 0.2407 - mape: 0.2407 - val_loss: 0.2324 - val_mape: 0.2324\n",
      "Epoch 61/100\n",
      "5399/5399 [==============================] - 1s 241us/step - loss: 0.2376 - mape: 0.2376 - val_loss: 0.2324 - val_mape: 0.2324\n",
      "Epoch 62/100\n",
      "5399/5399 [==============================] - 1s 260us/step - loss: 0.2417 - mape: 0.2417 - val_loss: 0.2376 - val_mape: 0.2376\n",
      "Epoch 63/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 0.2366 - mape: 0.2366 - val_loss: 0.2330 - val_mape: 0.2330\n",
      "Epoch 64/100\n",
      "5399/5399 [==============================] - 1s 257us/step - loss: 0.2396 - mape: 0.2396 - val_loss: 0.2362 - val_mape: 0.2362\n",
      "Epoch 65/100\n",
      "5399/5399 [==============================] - 1s 241us/step - loss: 0.2416 - mape: 0.2416 - val_loss: 0.2346 - val_mape: 0.2346\n",
      "Epoch 66/100\n",
      "5399/5399 [==============================] - 1s 236us/step - loss: 0.2399 - mape: 0.2399 - val_loss: 0.2403 - val_mape: 0.2403\n",
      "Epoch 67/100\n",
      "5399/5399 [==============================] - 1s 230us/step - loss: 0.2393 - mape: 0.2393 - val_loss: 0.2396 - val_mape: 0.2396\n",
      "Epoch 68/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2406 - mape: 0.2406 - val_loss: 0.2439 - val_mape: 0.2439\n",
      "Epoch 69/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 0.2400 - mape: 0.2400 - val_loss: 0.2408 - val_mape: 0.2408\n",
      "Epoch 70/100\n",
      "5399/5399 [==============================] - 1s 235us/step - loss: 0.2413 - mape: 0.2413 - val_loss: 0.2361 - val_mape: 0.2361\n",
      "Epoch 71/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2386 - mape: 0.2386 - val_loss: 0.2363 - val_mape: 0.2363\n",
      "Epoch 72/100\n",
      "5399/5399 [==============================] - 1s 230us/step - loss: 0.2419 - mape: 0.2419 - val_loss: 0.2432 - val_mape: 0.2432\n",
      "Epoch 73/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2403 - mape: 0.2403 - val_loss: 0.2351 - val_mape: 0.2351\n",
      "Epoch 74/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2409 - mape: 0.2409 - val_loss: 0.2331 - val_mape: 0.2331\n",
      "Epoch 75/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2404 - mape: 0.2404 - val_loss: 0.2428 - val_mape: 0.2428\n",
      "Epoch 76/100\n",
      "5399/5399 [==============================] - 1s 244us/step - loss: 0.2378 - mape: 0.2378 - val_loss: 0.2338 - val_mape: 0.2338\n",
      "Epoch 77/100\n",
      "5399/5399 [==============================] - 1s 256us/step - loss: 0.2428 - mape: 0.2428 - val_loss: 0.2332 - val_mape: 0.2332\n",
      "Epoch 78/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2430 - mape: 0.2430 - val_loss: 0.2348 - val_mape: 0.2348\n",
      "Epoch 79/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2376 - mape: 0.2376 - val_loss: 0.2541 - val_mape: 0.2541\n",
      "Epoch 80/100\n",
      "5399/5399 [==============================] - 1s 231us/step - loss: 0.2382 - mape: 0.2382 - val_loss: 0.2619 - val_mape: 0.2619\n",
      "Epoch 81/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 0.2386 - mape: 0.2386 - val_loss: 0.2446 - val_mape: 0.2446\n",
      "Epoch 82/100\n",
      "5399/5399 [==============================] - 1s 264us/step - loss: 0.2403 - mape: 0.2403 - val_loss: 0.2692 - val_mape: 0.2692\n",
      "Epoch 83/100\n",
      "5399/5399 [==============================] - 1s 264us/step - loss: 0.2379 - mape: 0.2379 - val_loss: 0.2439 - val_mape: 0.2439\n",
      "Epoch 84/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2393 - mape: 0.2393 - val_loss: 0.2361 - val_mape: 0.2361\n",
      "Epoch 85/100\n",
      "5399/5399 [==============================] - 1s 237us/step - loss: 0.2385 - mape: 0.2385 - val_loss: 0.2873 - val_mape: 0.2873\n",
      "Epoch 86/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2386 - mape: 0.2386 - val_loss: 0.2407 - val_mape: 0.2407\n",
      "Epoch 87/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2414 - mape: 0.2414 - val_loss: 0.2371 - val_mape: 0.2371\n",
      "Epoch 88/100\n",
      "5399/5399 [==============================] - 1s 239us/step - loss: 0.2421 - mape: 0.2421 - val_loss: 0.2368 - val_mape: 0.2368\n",
      "Epoch 89/100\n",
      "5399/5399 [==============================] - 1s 274us/step - loss: 0.2394 - mape: 0.2394 - val_loss: 0.2331 - val_mape: 0.2331\n",
      "Epoch 90/100\n",
      "5399/5399 [==============================] - 1s 252us/step - loss: 0.2410 - mape: 0.2410 - val_loss: 0.2440 - val_mape: 0.2440\n",
      "Epoch 91/100\n",
      "5399/5399 [==============================] - 1s 240us/step - loss: 0.2378 - mape: 0.2378 - val_loss: 0.2460 - val_mape: 0.2460\n",
      "Epoch 92/100\n",
      "5399/5399 [==============================] - 1s 239us/step - loss: 0.2392 - mape: 0.2392 - val_loss: 0.2471 - val_mape: 0.2471\n",
      "Epoch 93/100\n",
      "5399/5399 [==============================] - 1s 239us/step - loss: 0.2406 - mape: 0.2406 - val_loss: 0.2338 - val_mape: 0.2338\n",
      "Epoch 94/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2385 - mape: 0.2385 - val_loss: 0.2631 - val_mape: 0.2631\n",
      "Epoch 95/100\n",
      "5399/5399 [==============================] - 1s 232us/step - loss: 0.2385 - mape: 0.2385 - val_loss: 0.2386 - val_mape: 0.2386\n",
      "Epoch 96/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 0.2375 - mape: 0.2375 - val_loss: 0.2539 - val_mape: 0.2539\n",
      "Epoch 97/100\n",
      "5399/5399 [==============================] - 1s 239us/step - loss: 0.2378 - mape: 0.2378 - val_loss: 0.2350 - val_mape: 0.2350\n",
      "Epoch 98/100\n",
      "5399/5399 [==============================] - 1s 259us/step - loss: 0.2389 - mape: 0.2389 - val_loss: 0.2392 - val_mape: 0.2392\n",
      "Epoch 99/100\n",
      "5399/5399 [==============================] - 1s 234us/step - loss: 0.2388 - mape: 0.2388 - val_loss: 0.2385 - val_mape: 0.2385\n",
      "Epoch 100/100\n",
      "5399/5399 [==============================] - 1s 262us/step - loss: 0.2399 - mape: 0.2399 - val_loss: 0.2621 - val_mape: 0.2621\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform',  input_dim = 1))\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform'))\n",
    "classifier.add(Dense(1))\n",
    "classifier.compile(loss='mape', optimizer='adam', metrics=['mape'])\n",
    "history=classifier.fit(X_train, y_train,validation_data =[X_test,y_test], batch_size = 10, nb_epoch = 100)\n",
    "classifier.save('stock_prediction6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2314/2314 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2620604806994197"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape,MAPE = classifier.evaluate(X_test,y_test)\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mean_absolute_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1, units=9, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=9, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5399 samples, validate on 2314 samples\n",
      "Epoch 1/100\n",
      "5399/5399 [==============================] - 1s 233us/step - loss: 3886909.6019 - mse: 3886911.0000 - val_loss: 3564921.1106 - val_mse: 3564920.0000\n",
      "Epoch 2/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 2700652.9342 - mse: 2700651.2500 - val_loss: 1652483.9802 - val_mse: 1652484.0000\n",
      "Epoch 3/100\n",
      "5399/5399 [==============================] - 1s 190us/step - loss: 769370.5370 - mse: 769370.5000 - val_loss: 171818.2915 - val_mse: 171818.3281\n",
      "Epoch 4/100\n",
      "5399/5399 [==============================] - 1s 189us/step - loss: 42741.3240 - mse: 42741.3242 - val_loss: 1448.7846 - val_mse: 1448.7847\n",
      "Epoch 5/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 248.3352 - mse: 248.3353 - val_loss: 28.4350 - val_mse: 28.4350\n",
      "Epoch 6/100\n",
      "5399/5399 [==============================] - 1s 215us/step - loss: 27.2107 - mse: 27.2107 - val_loss: 27.9255 - val_mse: 27.9255\n",
      "Epoch 7/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 27.1255 - mse: 27.1255 - val_loss: 27.9669 - val_mse: 27.9669\n",
      "Epoch 8/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 27.1199 - mse: 27.1199 - val_loss: 27.9606 - val_mse: 27.9606\n",
      "Epoch 9/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 27.1333 - mse: 27.1333 - val_loss: 28.0309 - val_mse: 28.0309\n",
      "Epoch 10/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 27.1614 - mse: 27.1614 - val_loss: 27.9483 - val_mse: 27.9483\n",
      "Epoch 11/100\n",
      "5399/5399 [==============================] - 1s 199us/step - loss: 27.1968 - mse: 27.1968 - val_loss: 28.2631 - val_mse: 28.2631\n",
      "Epoch 12/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 27.2251 - mse: 27.2251 - val_loss: 28.2938 - val_mse: 28.2938\n",
      "Epoch 13/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 27.2182 - mse: 27.2182 - val_loss: 28.0762 - val_mse: 28.0761\n",
      "Epoch 14/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 27.3027 - mse: 27.3027 - val_loss: 27.9766 - val_mse: 27.9766\n",
      "Epoch 15/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 27.2524 - mse: 27.2524 - val_loss: 28.4688 - val_mse: 28.4688\n",
      "Epoch 16/100\n",
      "5399/5399 [==============================] - 1s 187us/step - loss: 27.4435 - mse: 27.4435 - val_loss: 28.5525 - val_mse: 28.5524\n",
      "Epoch 17/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 27.6017 - mse: 27.6017 - val_loss: 28.7073 - val_mse: 28.7073\n",
      "Epoch 18/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 27.5534 - mse: 27.5534 - val_loss: 28.0260 - val_mse: 28.0259\n",
      "Epoch 19/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 27.6224 - mse: 27.6224 - val_loss: 30.2804 - val_mse: 30.2804\n",
      "Epoch 20/100\n",
      "5399/5399 [==============================] - 1s 200us/step - loss: 27.8444 - mse: 27.8444 - val_loss: 28.9123 - val_mse: 28.9123\n",
      "Epoch 21/100\n",
      "5399/5399 [==============================] - 1s 211us/step - loss: 28.0100 - mse: 28.0100 - val_loss: 28.4637 - val_mse: 28.4637\n",
      "Epoch 22/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.2497 - mse: 28.2497 - val_loss: 32.9538 - val_mse: 32.9538\n",
      "Epoch 23/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 28.5486 - mse: 28.5486 - val_loss: 28.4693 - val_mse: 28.4693\n",
      "Epoch 24/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 28.6964 - mse: 28.6964 - val_loss: 30.3083 - val_mse: 30.3083\n",
      "Epoch 25/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 29.0859 - mse: 29.0860 - val_loss: 28.7747 - val_mse: 28.7747\n",
      "Epoch 26/100\n",
      "5399/5399 [==============================] - 1s 187us/step - loss: 28.5730 - mse: 28.5730 - val_loss: 28.4295 - val_mse: 28.4295\n",
      "Epoch 27/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.7697 - mse: 28.7697 - val_loss: 28.5430 - val_mse: 28.5430\n",
      "Epoch 28/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.5133 - mse: 28.5133 - val_loss: 30.3841 - val_mse: 30.3841\n",
      "Epoch 29/100\n",
      "5399/5399 [==============================] - 1s 199us/step - loss: 28.5238 - mse: 28.5238 - val_loss: 31.0196 - val_mse: 31.0196\n",
      "Epoch 30/100\n",
      "5399/5399 [==============================] - 1s 198us/step - loss: 29.1224 - mse: 29.1224 - val_loss: 27.9436 - val_mse: 27.9436\n",
      "Epoch 31/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 28.9142 - mse: 28.9142 - val_loss: 28.7246 - val_mse: 28.7246\n",
      "Epoch 32/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 29.4161 - mse: 29.4161 - val_loss: 29.1059 - val_mse: 29.1059\n",
      "Epoch 33/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 28.5501 - mse: 28.5501 - val_loss: 28.6940 - val_mse: 28.6940\n",
      "Epoch 34/100\n",
      "5399/5399 [==============================] - 1s 199us/step - loss: 29.1679 - mse: 29.1679 - val_loss: 30.6512 - val_mse: 30.6512\n",
      "Epoch 35/100\n",
      "5399/5399 [==============================] - 1s 198us/step - loss: 28.9784 - mse: 28.9784 - val_loss: 28.4524 - val_mse: 28.4524\n",
      "Epoch 36/100\n",
      "5399/5399 [==============================] - 1s 213us/step - loss: 28.5437 - mse: 28.5437 - val_loss: 28.8431 - val_mse: 28.8431\n",
      "Epoch 37/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 29.1219 - mse: 29.1219 - val_loss: 29.5401 - val_mse: 29.5401\n",
      "Epoch 38/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 28.9443 - mse: 28.9443 - val_loss: 28.2294 - val_mse: 28.2294\n",
      "Epoch 39/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 29.3841 - mse: 29.3840 - val_loss: 28.3170 - val_mse: 28.3170\n",
      "Epoch 40/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 28.9270 - mse: 28.9270 - val_loss: 28.3799 - val_mse: 28.3799\n",
      "Epoch 41/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 29.0982 - mse: 29.0982 - val_loss: 32.4649 - val_mse: 32.4649\n",
      "Epoch 42/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 29.2613 - mse: 29.2613 - val_loss: 28.4973 - val_mse: 28.4973\n",
      "Epoch 43/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 28.9507 - mse: 28.9507 - val_loss: 28.2727 - val_mse: 28.2727\n",
      "Epoch 44/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 28.9317 - mse: 28.9317 - val_loss: 29.8613 - val_mse: 29.8613\n",
      "Epoch 45/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 28.8049 - mse: 28.8049 - val_loss: 33.6549 - val_mse: 33.6549\n",
      "Epoch 46/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 29.4258 - mse: 29.4258 - val_loss: 29.1240 - val_mse: 29.1240\n",
      "Epoch 47/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.8123 - mse: 28.8123 - val_loss: 29.3061 - val_mse: 29.3061\n",
      "Epoch 48/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.6611 - mse: 28.6611 - val_loss: 28.5860 - val_mse: 28.5860\n",
      "Epoch 49/100\n",
      "5399/5399 [==============================] - 1s 187us/step - loss: 29.5860 - mse: 29.5860 - val_loss: 28.1763 - val_mse: 28.1763\n",
      "Epoch 50/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 29.1840 - mse: 29.1840 - val_loss: 28.4931 - val_mse: 28.4931\n",
      "Epoch 51/100\n",
      "5399/5399 [==============================] - 1s 204us/step - loss: 28.6545 - mse: 28.6545 - val_loss: 30.4267 - val_mse: 30.4267\n",
      "Epoch 52/100\n",
      "5399/5399 [==============================] - 1s 202us/step - loss: 29.3623 - mse: 29.3623 - val_loss: 31.5120 - val_mse: 31.5120\n",
      "Epoch 53/100\n",
      "5399/5399 [==============================] - 1s 210us/step - loss: 28.7714 - mse: 28.7714 - val_loss: 28.0189 - val_mse: 28.0189\n",
      "Epoch 54/100\n",
      "5399/5399 [==============================] - 1s 201us/step - loss: 28.7666 - mse: 28.7666 - val_loss: 29.0157 - val_mse: 29.0157\n",
      "Epoch 55/100\n",
      "5399/5399 [==============================] - 1s 200us/step - loss: 28.4430 - mse: 28.4430 - val_loss: 29.5478 - val_mse: 29.5477\n",
      "Epoch 56/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 29.2533 - mse: 29.2533 - val_loss: 28.6176 - val_mse: 28.6175\n",
      "Epoch 57/100\n",
      "5399/5399 [==============================] - 1s 187us/step - loss: 28.7469 - mse: 28.7469 - val_loss: 28.8704 - val_mse: 28.8704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.9271 - mse: 28.9271 - val_loss: 32.0491 - val_mse: 32.0491\n",
      "Epoch 59/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 28.8100 - mse: 28.8100 - val_loss: 29.2361 - val_mse: 29.2361\n",
      "Epoch 60/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 29.1372 - mse: 29.1372 - val_loss: 31.9572 - val_mse: 31.9572\n",
      "Epoch 61/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 28.6973 - mse: 28.6973 - val_loss: 33.4841 - val_mse: 33.4841\n",
      "Epoch 62/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 29.5213 - mse: 29.5213 - val_loss: 29.3395 - val_mse: 29.3395\n",
      "Epoch 63/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 28.6592 - mse: 28.6592 - val_loss: 28.0930 - val_mse: 28.0930\n",
      "Epoch 64/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 28.9304 - mse: 28.9304 - val_loss: 29.8946 - val_mse: 29.8946\n",
      "Epoch 65/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 28.8537 - mse: 28.8537 - val_loss: 28.1038 - val_mse: 28.1038\n",
      "Epoch 66/100\n",
      "5399/5399 [==============================] - 1s 207us/step - loss: 28.9298 - mse: 28.9298 - val_loss: 28.9965 - val_mse: 28.9965\n",
      "Epoch 67/100\n",
      "5399/5399 [==============================] - 1s 207us/step - loss: 28.8469 - mse: 28.8469 - val_loss: 29.0884 - val_mse: 29.0884\n",
      "Epoch 68/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 28.8083 - mse: 28.8083 - val_loss: 28.2515 - val_mse: 28.2515\n",
      "Epoch 69/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 29.1736 - mse: 29.1736 - val_loss: 29.1028 - val_mse: 29.1028\n",
      "Epoch 70/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 28.8538 - mse: 28.8538 - val_loss: 27.9379 - val_mse: 27.9379\n",
      "Epoch 71/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 28.9005 - mse: 28.9005 - val_loss: 28.0176 - val_mse: 28.0176\n",
      "Epoch 72/100\n",
      "5399/5399 [==============================] - 1s 196us/step - loss: 29.2482 - mse: 29.2482 - val_loss: 28.6773 - val_mse: 28.6773\n",
      "Epoch 73/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 28.9924 - mse: 28.9924 - val_loss: 29.2435 - val_mse: 29.2435\n",
      "Epoch 74/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 29.6952 - mse: 29.6952 - val_loss: 29.1148 - val_mse: 29.1148\n",
      "Epoch 75/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 29.2346 - mse: 29.2346 - val_loss: 28.0959 - val_mse: 28.0959\n",
      "Epoch 76/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 28.6758 - mse: 28.6758 - val_loss: 30.0211 - val_mse: 30.0211\n",
      "Epoch 77/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 28.9393 - mse: 28.9393 - val_loss: 28.2370 - val_mse: 28.2370\n",
      "Epoch 78/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 28.7728 - mse: 28.7728 - val_loss: 28.4718 - val_mse: 28.4718\n",
      "Epoch 79/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 29.2036 - mse: 29.2036 - val_loss: 27.9323 - val_mse: 27.9323\n",
      "Epoch 80/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.7576 - mse: 28.7575 - val_loss: 29.2961 - val_mse: 29.2961\n",
      "Epoch 81/100\n",
      "5399/5399 [==============================] - 1s 206us/step - loss: 28.9706 - mse: 28.9706 - val_loss: 29.0102 - val_mse: 29.0102\n",
      "Epoch 82/100\n",
      "5399/5399 [==============================] - 1s 205us/step - loss: 29.3520 - mse: 29.3520 - val_loss: 29.2439 - val_mse: 29.2439\n",
      "Epoch 83/100\n",
      "5399/5399 [==============================] - 1s 192us/step - loss: 28.7857 - mse: 28.7857 - val_loss: 28.1401 - val_mse: 28.1401\n",
      "Epoch 84/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 28.8969 - mse: 28.8969 - val_loss: 38.0021 - val_mse: 38.0021\n",
      "Epoch 85/100\n",
      "5399/5399 [==============================] - 1s 191us/step - loss: 29.3608 - mse: 29.3608 - val_loss: 28.7324 - val_mse: 28.7324\n",
      "Epoch 86/100\n",
      "5399/5399 [==============================] - 1s 199us/step - loss: 28.8624 - mse: 28.8624 - val_loss: 30.5134 - val_mse: 30.5134\n",
      "Epoch 87/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 28.8251 - mse: 28.8251 - val_loss: 28.3472 - val_mse: 28.3472\n",
      "Epoch 88/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 29.4814 - mse: 29.4814 - val_loss: 28.6437 - val_mse: 28.6437\n",
      "Epoch 89/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 29.0396 - mse: 29.0396 - val_loss: 30.8562 - val_mse: 30.8562\n",
      "Epoch 90/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 29.4044 - mse: 29.4044 - val_loss: 32.8671 - val_mse: 32.8670\n",
      "Epoch 91/100\n",
      "5399/5399 [==============================] - 1s 197us/step - loss: 29.3876 - mse: 29.3876 - val_loss: 28.5908 - val_mse: 28.5908\n",
      "Epoch 92/100\n",
      "5399/5399 [==============================] - 1s 194us/step - loss: 28.9277 - mse: 28.9277 - val_loss: 28.2800 - val_mse: 28.2800\n",
      "Epoch 93/100\n",
      "5399/5399 [==============================] - 1s 193us/step - loss: 28.8768 - mse: 28.8768 - val_loss: 29.8144 - val_mse: 29.8144\n",
      "Epoch 94/100\n",
      "5399/5399 [==============================] - 1s 201us/step - loss: 29.6106 - mse: 29.6106 - val_loss: 28.9413 - val_mse: 28.9413\n",
      "Epoch 95/100\n",
      "5399/5399 [==============================] - 1s 202us/step - loss: 29.2993 - mse: 29.2993 - val_loss: 28.5508 - val_mse: 28.5508\n",
      "Epoch 96/100\n",
      "5399/5399 [==============================] - 1s 202us/step - loss: 29.0230 - mse: 29.0230 - val_loss: 30.1894 - val_mse: 30.1894\n",
      "Epoch 97/100\n",
      "5399/5399 [==============================] - 1s 208us/step - loss: 29.0856 - mse: 29.0856 - val_loss: 28.7400 - val_mse: 28.7400\n",
      "Epoch 98/100\n",
      "5399/5399 [==============================] - 1s 206us/step - loss: 28.7025 - mse: 28.7025 - val_loss: 28.8745 - val_mse: 28.8745\n",
      "Epoch 99/100\n",
      "5399/5399 [==============================] - 1s 200us/step - loss: 29.3002 - mse: 29.3002 - val_loss: 28.0454 - val_mse: 28.0454\n",
      "Epoch 100/100\n",
      "5399/5399 [==============================] - 1s 195us/step - loss: 29.0976 - mse: 29.0976 - val_loss: 30.8944 - val_mse: 30.8944\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform',  input_dim = 1))\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform'))\n",
    "classifier.add(Dense(1))\n",
    "classifier.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "history=classifier.fit(X_train, y_train,validation_data =[X_test,y_test], batch_size = 10, nb_epoch = 100)\n",
    "classifier.save('stock_prediction4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2314/2314 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-99dea0a4489d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMAE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "MAE,mse = classifier.evaluate(X_test,y_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index:  [1102 1103 1104 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [   0    1    2 ... 1099 1100 1101]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 74us/step - loss: 3971.4644 - mean_absolute_error: 3971.4614 - mse: 125904248.0000\n",
      "1102/1102 [==============================] - 0s 26us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [1102 1103 1104 ... 2201 2202 2203]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 52us/step - loss: 615.5781 - mean_absolute_error: 615.5779 - mse: 1138795.1250\n",
      "1102/1102 [==============================] - 0s 29us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [2204 2205 2206 ... 3303 3304 3305]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 51us/step - loss: 668.7360 - mean_absolute_error: 668.7359 - mse: 1542722.0000\n",
      "1102/1102 [==============================] - 0s 27us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [3306 3307 3308 ... 4405 4406 4407]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 51us/step - loss: 629.4912 - mean_absolute_error: 629.4910 - mse: 1526067.6250\n",
      "1102/1102 [==============================] - 0s 27us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [4408 4409 4410 ... 5507 5508 5509]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 50us/step - loss: 563.2805 - mean_absolute_error: 563.2805 - mse: 1522069.2500\n",
      "1102/1102 [==============================] - 0s 29us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625], [1261.5070437450374, 1261.507080078125, 1685222.0]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [5510 5511 5512 ... 6609 6610 6611]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 50us/step - loss: 380.6928 - mean_absolute_error: 380.6928 - mse: 650105.6875\n",
      "1102/1102 [==============================] - 0s 25us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625], [1261.5070437450374, 1261.507080078125, 1685222.0], [168.71415660601994, 168.7141571044922, 33889.8671875]]\n",
      "Train Index:  [   0    1    2 ... 6609 6610 6611] \n",
      "\n",
      "Test Index:  [6612 6613 6614 ... 7710 7711 7712]\n",
      "Epoch 1/1\n",
      "6612/6612 [==============================] - 0s 49us/step - loss: 218.7660 - mean_absolute_error: 218.7661 - mse: 207314.4531\n",
      "1101/1101 [==============================] - 0s 27us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625], [1261.5070437450374, 1261.507080078125, 1685222.0], [168.71415660601994, 168.7141571044922, 33889.8671875], [809.9979797973078, 809.998046875, 670389.9375]]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=7)\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "        model.fit(X_train, y_train)\n",
    "        return model.evaluate(X_test, y_test)\n",
    "\n",
    "scores_SVM=[]\n",
    "\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    print(\"Train Index: \", train_index, \"\\n\")\n",
    "    print(\"Test Index: \", test_index)\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    scores_SVM.append(get_score(classifier, X_train, X_test, y_train, y_test))\n",
    "    print(scores_SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
