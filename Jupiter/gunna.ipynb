{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Divisoinal Secretary Area</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>DOY</th>\n",
       "      <th>Rainfalls</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temparature</th>\n",
       "      <th>Harvest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01. Ampara</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>91</td>\n",
       "      <td>0.39</td>\n",
       "      <td>69.43</td>\n",
       "      <td>29.18</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>92</td>\n",
       "      <td>0.23</td>\n",
       "      <td>71.53</td>\n",
       "      <td>28.71</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>93</td>\n",
       "      <td>0.08</td>\n",
       "      <td>68.92</td>\n",
       "      <td>28.48</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>61.05</td>\n",
       "      <td>28.57</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>59.81</td>\n",
       "      <td>28.71</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Divisoinal Secretary Area      lat       lon  year  DOY  Rainfalls  \\\n",
       "0                01. Ampara  7.29191  81.67841  2019   91       0.39   \n",
       "1                       NaN  7.29191  81.67841  2019   92       0.23   \n",
       "2                       NaN  7.29191  81.67841  2019   93       0.08   \n",
       "3                       NaN  7.29191  81.67841  2019   94       0.01   \n",
       "4                       NaN  7.29191  81.67841  2019   95       0.05   \n",
       "\n",
       "   Humidity  Temparature   Harvest  \n",
       "0     69.43        29.18  10770.38  \n",
       "1     71.53        28.71  10770.38  \n",
       "2     68.92        28.48  10770.38  \n",
       "3     61.05        28.57  10770.38  \n",
       "4     59.81        28.71  10770.38  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\Acer\\Downloads\\Ann_model_sample.csv', header =0)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Divisoinal Secretary Area</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>DOY</th>\n",
       "      <th>Rainfalls</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temparature</th>\n",
       "      <th>Harvest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01. Ampara</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>91</td>\n",
       "      <td>0.39</td>\n",
       "      <td>69.43</td>\n",
       "      <td>29.18</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>92</td>\n",
       "      <td>0.23</td>\n",
       "      <td>71.53</td>\n",
       "      <td>28.71</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>93</td>\n",
       "      <td>0.08</td>\n",
       "      <td>68.92</td>\n",
       "      <td>28.48</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>61.05</td>\n",
       "      <td>28.57</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.29191</td>\n",
       "      <td>81.67841</td>\n",
       "      <td>2019</td>\n",
       "      <td>95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>59.81</td>\n",
       "      <td>28.71</td>\n",
       "      <td>10770.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Divisoinal Secretary Area      lat       lon  year  DOY  Rainfalls  \\\n",
       "0                01. Ampara  7.29191  81.67841  2019   91       0.39   \n",
       "1                       NaN  7.29191  81.67841  2019   92       0.23   \n",
       "2                       NaN  7.29191  81.67841  2019   93       0.08   \n",
       "3                       NaN  7.29191  81.67841  2019   94       0.01   \n",
       "4                       NaN  7.29191  81.67841  2019   95       0.05   \n",
       "\n",
       "   Humidity  Temparature   Harvest  \n",
       "0     69.43        29.18  10770.38  \n",
       "1     71.53        28.71  10770.38  \n",
       "2     68.92        28.48  10770.38  \n",
       "3     61.05        28.57  10770.38  \n",
       "4     59.81        28.71  10770.38  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.29191]\n",
      " [7.29191]\n",
      " [7.29191]\n",
      " ...\n",
      " [7.28361]\n",
      " [7.28361]\n",
      " [7.28361]]\n",
      "[81.67841 81.67841 81.67841 ... 81.81121 81.81121 81.81121]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 1:2].values\n",
    "y = dataset.iloc[:, 2].values\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2846, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2846,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1, units=9, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=9, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2846 samples, validate on 1220 samples\n",
      "Epoch 1/100\n",
      "2846/2846 [==============================] - 1s 265us/step - loss: 76.2959 - mean_absolute_error: 76.2959 - mse: 5849.6040 - val_loss: 62.4515 - val_mean_absolute_error: 62.4514 - val_mse: 3900.2869\n",
      "Epoch 2/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 24.6517 - mean_absolute_error: 24.6517 - mse: 1108.9402 - val_loss: 0.2605 - val_mean_absolute_error: 0.2605 - val_mse: 0.1208\n",
      "Epoch 3/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.2378 - mean_absolute_error: 0.2378 - mse: 0.0948 - val_loss: 0.2257 - val_mean_absolute_error: 0.2257 - val_mse: 0.0977\n",
      "Epoch 4/100\n",
      "2846/2846 [==============================] - 1s 201us/step - loss: 0.2400 - mean_absolute_error: 0.2400 - mse: 0.1098 - val_loss: 0.2241 - val_mean_absolute_error: 0.2241 - val_mse: 0.1063\n",
      "Epoch 5/100\n",
      "2846/2846 [==============================] - 1s 215us/step - loss: 0.2402 - mean_absolute_error: 0.2402 - mse: 0.1087 - val_loss: 0.2191 - val_mean_absolute_error: 0.2191 - val_mse: 0.0828\n",
      "Epoch 6/100\n",
      "2846/2846 [==============================] - 1s 212us/step - loss: 0.2283 - mean_absolute_error: 0.2283 - mse: 0.0883 - val_loss: 0.2569 - val_mean_absolute_error: 0.2569 - val_mse: 0.0881\n",
      "Epoch 7/100\n",
      "2846/2846 [==============================] - 1s 201us/step - loss: 0.2412 - mean_absolute_error: 0.2412 - mse: 0.0974 - val_loss: 0.2317 - val_mean_absolute_error: 0.2317 - val_mse: 0.0949\n",
      "Epoch 8/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2351 - mean_absolute_error: 0.2351 - mse: 0.0933 - val_loss: 0.2315 - val_mean_absolute_error: 0.2315 - val_mse: 0.0996\n",
      "Epoch 9/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2356 - mean_absolute_error: 0.2356 - mse: 0.0946 - val_loss: 0.2552 - val_mean_absolute_error: 0.2552 - val_mse: 0.1073\n",
      "Epoch 10/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2489 - mean_absolute_error: 0.2489 - mse: 0.1112 - val_loss: 0.2268 - val_mean_absolute_error: 0.2268 - val_mse: 0.0925\n",
      "Epoch 11/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.2428 - mean_absolute_error: 0.2428 - mse: 0.1150 - val_loss: 0.2596 - val_mean_absolute_error: 0.2596 - val_mse: 0.1104\n",
      "Epoch 12/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2374 - mean_absolute_error: 0.2374 - mse: 0.1041 - val_loss: 0.2916 - val_mean_absolute_error: 0.2916 - val_mse: 0.1943\n",
      "Epoch 13/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2398 - mean_absolute_error: 0.2398 - mse: 0.0979 - val_loss: 0.2279 - val_mean_absolute_error: 0.2279 - val_mse: 0.0903\n",
      "Epoch 14/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.2324 - mean_absolute_error: 0.2324 - mse: 0.0966 - val_loss: 0.2374 - val_mean_absolute_error: 0.2374 - val_mse: 0.0799\n",
      "Epoch 15/100\n",
      "2846/2846 [==============================] - 1s 201us/step - loss: 0.2277 - mean_absolute_error: 0.2277 - mse: 0.0913 - val_loss: 0.2350 - val_mean_absolute_error: 0.2350 - val_mse: 0.0930\n",
      "Epoch 16/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.2325 - mean_absolute_error: 0.2325 - mse: 0.0932 - val_loss: 0.2425 - val_mean_absolute_error: 0.2425 - val_mse: 0.1084\n",
      "Epoch 17/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.2297 - mean_absolute_error: 0.2297 - mse: 0.0917 - val_loss: 0.2354 - val_mean_absolute_error: 0.2354 - val_mse: 0.0843\n",
      "Epoch 18/100\n",
      "2846/2846 [==============================] - 1s 190us/step - loss: 0.2355 - mean_absolute_error: 0.2355 - mse: 0.0930 - val_loss: 0.2470 - val_mean_absolute_error: 0.2470 - val_mse: 0.0840\n",
      "Epoch 19/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2312 - mean_absolute_error: 0.2312 - mse: 0.0903 - val_loss: 0.2439 - val_mean_absolute_error: 0.2439 - val_mse: 0.0955\n",
      "Epoch 20/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.2363 - mean_absolute_error: 0.2363 - mse: 0.1136 - val_loss: 0.2796 - val_mean_absolute_error: 0.2796 - val_mse: 0.1435\n",
      "Epoch 21/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2311 - mean_absolute_error: 0.2311 - mse: 0.1031 - val_loss: 0.2412 - val_mean_absolute_error: 0.2412 - val_mse: 0.0906\n",
      "Epoch 22/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.2282 - mean_absolute_error: 0.2282 - mse: 0.0914 - val_loss: 0.2223 - val_mean_absolute_error: 0.2223 - val_mse: 0.0826\n",
      "Epoch 23/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.2357 - mean_absolute_error: 0.2357 - mse: 0.1011 - val_loss: 0.2540 - val_mean_absolute_error: 0.2540 - val_mse: 0.1114\n",
      "Epoch 24/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2399 - mean_absolute_error: 0.2399 - mse: 0.1040 - val_loss: 0.2285 - val_mean_absolute_error: 0.2285 - val_mse: 0.0912\n",
      "Epoch 25/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.2273 - mean_absolute_error: 0.2273 - mse: 0.0923 - val_loss: 0.2563 - val_mean_absolute_error: 0.2563 - val_mse: 0.1130\n",
      "Epoch 26/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2299 - mean_absolute_error: 0.2299 - mse: 0.0897 - val_loss: 0.2298 - val_mean_absolute_error: 0.2298 - val_mse: 0.0946\n",
      "Epoch 27/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2323 - mean_absolute_error: 0.2323 - mse: 0.0938 - val_loss: 0.2595 - val_mean_absolute_error: 0.2595 - val_mse: 0.1155\n",
      "Epoch 28/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2340 - mean_absolute_error: 0.2340 - mse: 0.0946 - val_loss: 0.2258 - val_mean_absolute_error: 0.2258 - val_mse: 0.0944\n",
      "Epoch 29/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2389 - mean_absolute_error: 0.2389 - mse: 0.1029 - val_loss: 0.2350 - val_mean_absolute_error: 0.2350 - val_mse: 0.1142\n",
      "Epoch 30/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2361 - mean_absolute_error: 0.2361 - mse: 0.1093 - val_loss: 0.2605 - val_mean_absolute_error: 0.2605 - val_mse: 0.1273\n",
      "Epoch 31/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2360 - mean_absolute_error: 0.2360 - mse: 0.1016 - val_loss: 0.2377 - val_mean_absolute_error: 0.2377 - val_mse: 0.0826\n",
      "Epoch 32/100\n",
      "2846/2846 [==============================] - 1s 203us/step - loss: 0.2320 - mean_absolute_error: 0.2320 - mse: 0.0958 - val_loss: 0.2239 - val_mean_absolute_error: 0.2239 - val_mse: 0.1014\n",
      "Epoch 33/100\n",
      "2846/2846 [==============================] - 1s 214us/step - loss: 0.2375 - mean_absolute_error: 0.2375 - mse: 0.0999 - val_loss: 0.2385 - val_mean_absolute_error: 0.2385 - val_mse: 0.1106\n",
      "Epoch 34/100\n",
      "2846/2846 [==============================] - 1s 223us/step - loss: 0.2299 - mean_absolute_error: 0.2299 - mse: 0.0960 - val_loss: 0.2446 - val_mean_absolute_error: 0.2446 - val_mse: 0.0887\n",
      "Epoch 35/100\n",
      "2846/2846 [==============================] - 1s 208us/step - loss: 0.2405 - mean_absolute_error: 0.2405 - mse: 0.1080 - val_loss: 0.2225 - val_mean_absolute_error: 0.2225 - val_mse: 0.0827\n",
      "Epoch 36/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2313 - mean_absolute_error: 0.2313 - mse: 0.0898 - val_loss: 0.2497 - val_mean_absolute_error: 0.2497 - val_mse: 0.0862\n",
      "Epoch 37/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2288 - mean_absolute_error: 0.2288 - mse: 0.0926 - val_loss: 0.2865 - val_mean_absolute_error: 0.2865 - val_mse: 0.1472\n",
      "Epoch 38/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2330 - mean_absolute_error: 0.2330 - mse: 0.0953 - val_loss: 0.2252 - val_mean_absolute_error: 0.2252 - val_mse: 0.0821\n",
      "Epoch 39/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2306 - mean_absolute_error: 0.2306 - mse: 0.0924 - val_loss: 0.2472 - val_mean_absolute_error: 0.2472 - val_mse: 0.0881\n",
      "Epoch 40/100\n",
      "2846/2846 [==============================] - 1s 207us/step - loss: 0.2354 - mean_absolute_error: 0.2354 - mse: 0.0957 - val_loss: 0.2214 - val_mean_absolute_error: 0.2214 - val_mse: 0.0818\n",
      "Epoch 41/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2394 - mean_absolute_error: 0.2394 - mse: 0.1014 - val_loss: 0.2334 - val_mean_absolute_error: 0.2334 - val_mse: 0.0804\n",
      "Epoch 42/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2300 - mean_absolute_error: 0.2300 - mse: 0.0901 - val_loss: 0.2459 - val_mean_absolute_error: 0.2459 - val_mse: 0.1122\n",
      "Epoch 43/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.2286 - mean_absolute_error: 0.2286 - mse: 0.0917 - val_loss: 0.2284 - val_mean_absolute_error: 0.2284 - val_mse: 0.0853\n",
      "Epoch 44/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.2284 - mean_absolute_error: 0.2284 - mse: 0.0899 - val_loss: 0.2293 - val_mean_absolute_error: 0.2293 - val_mse: 0.0903\n",
      "Epoch 45/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.2333 - mean_absolute_error: 0.2333 - mse: 0.0936 - val_loss: 0.2480 - val_mean_absolute_error: 0.2480 - val_mse: 0.1027\n",
      "Epoch 46/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2283 - mean_absolute_error: 0.2283 - mse: 0.0901 - val_loss: 0.2202 - val_mean_absolute_error: 0.2202 - val_mse: 0.0909\n",
      "Epoch 47/100\n",
      "2846/2846 [==============================] - 1s 191us/step - loss: 0.2386 - mean_absolute_error: 0.2386 - mse: 0.1010 - val_loss: 0.2616 - val_mean_absolute_error: 0.2616 - val_mse: 0.1317\n",
      "Epoch 48/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.2347 - mean_absolute_error: 0.2347 - mse: 0.0976 - val_loss: 0.2284 - val_mean_absolute_error: 0.2284 - val_mse: 0.0979\n",
      "Epoch 49/100\n",
      "2846/2846 [==============================] - 1s 205us/step - loss: 0.2321 - mean_absolute_error: 0.2321 - mse: 0.0950 - val_loss: 0.2320 - val_mean_absolute_error: 0.2320 - val_mse: 0.0935\n",
      "Epoch 50/100\n",
      "2846/2846 [==============================] - 1s 207us/step - loss: 0.2365 - mean_absolute_error: 0.2365 - mse: 0.0940 - val_loss: 0.2336 - val_mean_absolute_error: 0.2336 - val_mse: 0.1016\n",
      "Epoch 51/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2343 - mean_absolute_error: 0.2343 - mse: 0.0969 - val_loss: 0.2468 - val_mean_absolute_error: 0.2468 - val_mse: 0.0843\n",
      "Epoch 52/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.2404 - mean_absolute_error: 0.2404 - mse: 0.1056 - val_loss: 0.2266 - val_mean_absolute_error: 0.2266 - val_mse: 0.1026\n",
      "Epoch 53/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2333 - mean_absolute_error: 0.2333 - mse: 0.0901 - val_loss: 0.2335 - val_mean_absolute_error: 0.2335 - val_mse: 0.1047\n",
      "Epoch 54/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.2431 - mean_absolute_error: 0.2431 - mse: 0.1078 - val_loss: 0.2537 - val_mean_absolute_error: 0.2537 - val_mse: 0.1076\n",
      "Epoch 55/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2274 - mean_absolute_error: 0.2274 - mse: 0.0902 - val_loss: 0.2651 - val_mean_absolute_error: 0.2651 - val_mse: 0.1161\n",
      "Epoch 56/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2354 - mean_absolute_error: 0.2354 - mse: 0.1040 - val_loss: 0.2430 - val_mean_absolute_error: 0.2430 - val_mse: 0.0818\n",
      "Epoch 57/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2291 - mean_absolute_error: 0.2291 - mse: 0.0905 - val_loss: 0.2291 - val_mean_absolute_error: 0.2291 - val_mse: 0.0898\n",
      "Epoch 58/100\n",
      "2846/2846 [==============================] - 1s 207us/step - loss: 0.2348 - mean_absolute_error: 0.2348 - mse: 0.0938 - val_loss: 0.2292 - val_mean_absolute_error: 0.2292 - val_mse: 0.0967\n",
      "Epoch 59/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2313 - mean_absolute_error: 0.2313 - mse: 0.0906 - val_loss: 0.2227 - val_mean_absolute_error: 0.2227 - val_mse: 0.0828\n",
      "Epoch 60/100\n",
      "2846/2846 [==============================] - 1s 206us/step - loss: 0.2365 - mean_absolute_error: 0.2365 - mse: 0.0963 - val_loss: 0.2655 - val_mean_absolute_error: 0.2655 - val_mse: 0.0920\n",
      "Epoch 61/100\n",
      "2846/2846 [==============================] - 1s 212us/step - loss: 0.2344 - mean_absolute_error: 0.2344 - mse: 0.0921 - val_loss: 0.2384 - val_mean_absolute_error: 0.2384 - val_mse: 0.0853\n",
      "Epoch 62/100\n",
      "2846/2846 [==============================] - 1s 213us/step - loss: 0.2322 - mean_absolute_error: 0.2322 - mse: 0.0943 - val_loss: 0.2270 - val_mean_absolute_error: 0.2270 - val_mse: 0.0883\n",
      "Epoch 63/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.2334 - mean_absolute_error: 0.2334 - mse: 0.0931 - val_loss: 0.2208 - val_mean_absolute_error: 0.2208 - val_mse: 0.0820\n",
      "Epoch 64/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.2335 - mean_absolute_error: 0.2335 - mse: 0.0998 - val_loss: 0.2247 - val_mean_absolute_error: 0.2247 - val_mse: 0.0952\n",
      "Epoch 65/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2327 - mean_absolute_error: 0.2327 - mse: 0.1042 - val_loss: 0.2330 - val_mean_absolute_error: 0.2330 - val_mse: 0.0854\n",
      "Epoch 66/100\n",
      "2846/2846 [==============================] - 1s 206us/step - loss: 0.2319 - mean_absolute_error: 0.2319 - mse: 0.0900 - val_loss: 0.2233 - val_mean_absolute_error: 0.2233 - val_mse: 0.0809\n",
      "Epoch 67/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.2330 - mean_absolute_error: 0.2330 - mse: 0.0983 - val_loss: 0.2537 - val_mean_absolute_error: 0.2537 - val_mse: 0.0930\n",
      "Epoch 68/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.2323 - mean_absolute_error: 0.2323 - mse: 0.0913 - val_loss: 0.2225 - val_mean_absolute_error: 0.2225 - val_mse: 0.0873\n",
      "Epoch 69/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2344 - mean_absolute_error: 0.2344 - mse: 0.0936 - val_loss: 0.2394 - val_mean_absolute_error: 0.2394 - val_mse: 0.1098\n",
      "Epoch 70/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.2348 - mean_absolute_error: 0.2348 - mse: 0.0975 - val_loss: 0.2270 - val_mean_absolute_error: 0.2270 - val_mse: 0.0839\n",
      "Epoch 71/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.2437 - mean_absolute_error: 0.2437 - mse: 0.1065 - val_loss: 0.2752 - val_mean_absolute_error: 0.2752 - val_mse: 0.1274\n",
      "Epoch 72/100\n",
      "2846/2846 [==============================] - 1s 213us/step - loss: 0.2327 - mean_absolute_error: 0.2327 - mse: 0.0977 - val_loss: 0.2241 - val_mean_absolute_error: 0.2241 - val_mse: 0.0848\n",
      "Epoch 73/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.2378 - mean_absolute_error: 0.2378 - mse: 0.0958 - val_loss: 0.2535 - val_mean_absolute_error: 0.2535 - val_mse: 0.0915\n",
      "Epoch 74/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.2393 - mean_absolute_error: 0.2393 - mse: 0.1012 - val_loss: 0.2259 - val_mean_absolute_error: 0.2259 - val_mse: 0.0873\n",
      "Epoch 75/100\n",
      "2846/2846 [==============================] - 1s 209us/step - loss: 0.2409 - mean_absolute_error: 0.2409 - mse: 0.1000 - val_loss: 0.2454 - val_mean_absolute_error: 0.2454 - val_mse: 0.0836\n",
      "Epoch 76/100\n",
      "2846/2846 [==============================] - 1s 201us/step - loss: 0.2395 - mean_absolute_error: 0.2395 - mse: 0.0975 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030 - val_mse: 0.1196\n",
      "Epoch 77/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.2398 - mean_absolute_error: 0.2398 - mse: 0.1064 - val_loss: 0.2585 - val_mean_absolute_error: 0.2585 - val_mse: 0.1209\n",
      "Epoch 78/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.2381 - mean_absolute_error: 0.2381 - mse: 0.1045 - val_loss: 0.2446 - val_mean_absolute_error: 0.2446 - val_mse: 0.0993\n",
      "Epoch 79/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2284 - mean_absolute_error: 0.2284 - mse: 0.1016 - val_loss: 0.2196 - val_mean_absolute_error: 0.2196 - val_mse: 0.0881\n",
      "Epoch 80/100\n",
      "2846/2846 [==============================] - 1s 190us/step - loss: 0.2355 - mean_absolute_error: 0.2355 - mse: 0.0969 - val_loss: 0.2207 - val_mean_absolute_error: 0.2207 - val_mse: 0.0818\n",
      "Epoch 81/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2465 - mean_absolute_error: 0.2465 - mse: 0.1156 - val_loss: 0.2238 - val_mean_absolute_error: 0.2238 - val_mse: 0.0904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.2348 - mean_absolute_error: 0.2348 - mse: 0.1055 - val_loss: 0.2322 - val_mean_absolute_error: 0.2322 - val_mse: 0.1002\n",
      "Epoch 83/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2331 - mean_absolute_error: 0.2331 - mse: 0.1045 - val_loss: 0.2219 - val_mean_absolute_error: 0.2219 - val_mse: 0.0827\n",
      "Epoch 84/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2276 - mean_absolute_error: 0.2276 - mse: 0.0956 - val_loss: 0.2892 - val_mean_absolute_error: 0.2892 - val_mse: 0.1600\n",
      "Epoch 85/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2347 - mean_absolute_error: 0.2347 - mse: 0.0948 - val_loss: 0.2216 - val_mean_absolute_error: 0.2216 - val_mse: 0.0831\n",
      "Epoch 86/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2340 - mean_absolute_error: 0.2340 - mse: 0.1034 - val_loss: 0.2592 - val_mean_absolute_error: 0.2592 - val_mse: 0.1154\n",
      "Epoch 87/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.2331 - mean_absolute_error: 0.2331 - mse: 0.0930 - val_loss: 0.2276 - val_mean_absolute_error: 0.2276 - val_mse: 0.0924\n",
      "Epoch 88/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2355 - mean_absolute_error: 0.2355 - mse: 0.1042 - val_loss: 0.2951 - val_mean_absolute_error: 0.2951 - val_mse: 0.1689\n",
      "Epoch 89/100\n",
      "2846/2846 [==============================] - 1s 210us/step - loss: 0.2325 - mean_absolute_error: 0.2325 - mse: 0.1034 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598 - val_mse: 0.0972\n",
      "Epoch 90/100\n",
      "2846/2846 [==============================] - 1s 205us/step - loss: 0.2340 - mean_absolute_error: 0.2340 - mse: 0.0904 - val_loss: 0.2228 - val_mean_absolute_error: 0.2228 - val_mse: 0.0828\n",
      "Epoch 91/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.2390 - mean_absolute_error: 0.2390 - mse: 0.1068 - val_loss: 0.2290 - val_mean_absolute_error: 0.2290 - val_mse: 0.0916\n",
      "Epoch 92/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.2364 - mean_absolute_error: 0.2364 - mse: 0.1000 - val_loss: 0.2288 - val_mean_absolute_error: 0.2288 - val_mse: 0.0804\n",
      "Epoch 93/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.2392 - mean_absolute_error: 0.2392 - mse: 0.1011 - val_loss: 0.3000 - val_mean_absolute_error: 0.3000 - val_mse: 0.1709\n",
      "Epoch 94/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2299 - mean_absolute_error: 0.2299 - mse: 0.0889 - val_loss: 0.2980 - val_mean_absolute_error: 0.2980 - val_mse: 0.1619\n",
      "Epoch 95/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2365 - mean_absolute_error: 0.2365 - mse: 0.0988 - val_loss: 0.2575 - val_mean_absolute_error: 0.2575 - val_mse: 0.0934\n",
      "Epoch 96/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2361 - mean_absolute_error: 0.2361 - mse: 0.1009 - val_loss: 0.2347 - val_mean_absolute_error: 0.2347 - val_mse: 0.0961\n",
      "Epoch 97/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2367 - mean_absolute_error: 0.2367 - mse: 0.0990 - val_loss: 0.2279 - val_mean_absolute_error: 0.2279 - val_mse: 0.0886\n",
      "Epoch 98/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2312 - mean_absolute_error: 0.2312 - mse: 0.0986 - val_loss: 0.2243 - val_mean_absolute_error: 0.2243 - val_mse: 0.0838\n",
      "Epoch 99/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.2357 - mean_absolute_error: 0.2357 - mse: 0.0921 - val_loss: 0.2215 - val_mean_absolute_error: 0.2215 - val_mse: 0.0846\n",
      "Epoch 100/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.2341 - mean_absolute_error: 0.2341 - mse: 0.0959 - val_loss: 0.2446 - val_mean_absolute_error: 0.2446 - val_mse: 0.0942\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform',  input_dim = 1))\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform'))\n",
    "classifier.add(Dense(1))\n",
    "classifier.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error','mse'])\n",
    "history=classifier.fit(X_train, y_train,validation_data =[X_test,y_test], batch_size = 10, nb_epoch = 100)\n",
    "classifier.save('stock_prediction6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model('stock_prediction6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220/1220 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24457823331238793"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE,mse,loss = classifier.evaluate(X_test,y_test)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mean_absolute_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1, units=9, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=9, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Acer\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2846 samples, validate on 1220 samples\n",
      "Epoch 1/100\n",
      "2846/2846 [==============================] - 1s 283us/step - loss: 5805.2636 - mse: 5805.2666 - val_loss: 3875.8472 - val_mse: 3875.8467\n",
      "Epoch 2/100\n",
      "2846/2846 [==============================] - 1s 213us/step - loss: 1391.8317 - mse: 1391.8315 - val_loss: 52.7629 - val_mse: 52.7629\n",
      "Epoch 3/100\n",
      "2846/2846 [==============================] - 1s 205us/step - loss: 6.2232 - mse: 6.2232 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 4/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 5/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0796 - val_mse: 0.0796\n",
      "Epoch 6/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 7/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 8/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 9/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 10/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.0740 - mse: 0.0740 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 11/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 12/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 13/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 14/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0796 - val_mse: 0.0796\n",
      "Epoch 15/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0750 - mse: 0.0750 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 16/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.0749 - mse: 0.0749 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 17/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 18/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0753 - mse: 0.0753 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 19/100\n",
      "2846/2846 [==============================] - 1s 203us/step - loss: 0.0765 - mse: 0.0765 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 20/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 21/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0775 - mse: 0.0775 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 22/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 23/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.0771 - mse: 0.0771 - val_loss: 0.0810 - val_mse: 0.0810\n",
      "Epoch 24/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0784 - mse: 0.0784 - val_loss: 0.0846 - val_mse: 0.0846\n",
      "Epoch 25/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0885 - val_mse: 0.0885\n",
      "Epoch 26/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0793 - mse: 0.0793 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 27/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0792 - mse: 0.0792 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 28/100\n",
      "2846/2846 [==============================] - 1s 203us/step - loss: 0.0793 - mse: 0.0793 - val_loss: 0.1080 - val_mse: 0.1080\n",
      "Epoch 29/100\n",
      "2846/2846 [==============================] - 1s 210us/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 30/100\n",
      "2846/2846 [==============================] - 1s 209us/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.0900 - val_mse: 0.0900\n",
      "Epoch 31/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.0835 - mse: 0.0835 - val_loss: 0.0914 - val_mse: 0.0914\n",
      "Epoch 32/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 33/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0815 - mse: 0.0815 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 34/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.1059 - val_mse: 0.1059\n",
      "Epoch 35/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0865 - mse: 0.0865 - val_loss: 0.1133 - val_mse: 0.1133\n",
      "Epoch 36/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.0820 - mse: 0.0820 - val_loss: 0.1179 - val_mse: 0.1179\n",
      "Epoch 37/100\n",
      "2846/2846 [==============================] - 1s 187us/step - loss: 0.0854 - mse: 0.0854 - val_loss: 0.0817 - val_mse: 0.0817\n",
      "Epoch 38/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 39/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0811 - mse: 0.0811 - val_loss: 0.1010 - val_mse: 0.1010\n",
      "Epoch 40/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0866 - mse: 0.0866 - val_loss: 0.1155 - val_mse: 0.1155\n",
      "Epoch 41/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0884 - mse: 0.0884 - val_loss: 0.0860 - val_mse: 0.0860\n",
      "Epoch 42/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.1056 - val_mse: 0.1056\n",
      "Epoch 43/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0922 - mse: 0.0922 - val_loss: 0.0864 - val_mse: 0.0864\n",
      "Epoch 44/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.1172 - val_mse: 0.1172\n",
      "Epoch 45/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.0825 - mse: 0.0825 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 46/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.0921 - mse: 0.0921 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 47/100\n",
      "2846/2846 [==============================] - 1s 201us/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0957 - val_mse: 0.0957\n",
      "Epoch 48/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 49/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0842 - mse: 0.0842 - val_loss: 0.0936 - val_mse: 0.0936\n",
      "Epoch 50/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 51/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0914 - val_mse: 0.0914\n",
      "Epoch 52/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 53/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.0985 - val_mse: 0.0985\n",
      "Epoch 54/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.0856 - mse: 0.0856 - val_loss: 0.0888 - val_mse: 0.0888\n",
      "Epoch 55/100\n",
      "2846/2846 [==============================] - 1s 203us/step - loss: 0.0867 - mse: 0.0867 - val_loss: 0.0999 - val_mse: 0.0999\n",
      "Epoch 56/100\n",
      "2846/2846 [==============================] - 1s 203us/step - loss: 0.0881 - mse: 0.0881 - val_loss: 0.1026 - val_mse: 0.1026\n",
      "Epoch 57/100\n",
      "2846/2846 [==============================] - 1s 205us/step - loss: 0.0874 - mse: 0.0874 - val_loss: 0.1113 - val_mse: 0.1113\n",
      "Epoch 58/100\n",
      "2846/2846 [==============================] - 1s 207us/step - loss: 0.0819 - mse: 0.0819 - val_loss: 0.0989 - val_mse: 0.0989\n",
      "Epoch 59/100\n",
      "2846/2846 [==============================] - 1s 222us/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0966 - val_mse: 0.0966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0854 - mse: 0.0854 - val_loss: 0.1238 - val_mse: 0.1238\n",
      "Epoch 61/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.0909 - mse: 0.0909 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 62/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.0835 - mse: 0.0835 - val_loss: 0.0905 - val_mse: 0.0905\n",
      "Epoch 63/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.1140 - val_mse: 0.1140\n",
      "Epoch 64/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0916 - val_mse: 0.0916\n",
      "Epoch 65/100\n",
      "2846/2846 [==============================] - 1s 214us/step - loss: 0.0938 - mse: 0.0938 - val_loss: 0.0898 - val_mse: 0.0898\n",
      "Epoch 66/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 67/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.1137 - val_mse: 0.1137\n",
      "Epoch 68/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0935 - val_mse: 0.0935\n",
      "Epoch 69/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0820 - mse: 0.0820 - val_loss: 0.0886 - val_mse: 0.0886\n",
      "Epoch 70/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.0866 - mse: 0.0866 - val_loss: 0.0962 - val_mse: 0.0962\n",
      "Epoch 71/100\n",
      "2846/2846 [==============================] - 1s 193us/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 72/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0865 - mse: 0.0865 - val_loss: 0.0903 - val_mse: 0.0903\n",
      "Epoch 73/100\n",
      "2846/2846 [==============================] - 1s 191us/step - loss: 0.0856 - mse: 0.0856 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 74/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.1041 - val_mse: 0.1041\n",
      "Epoch 75/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0936 - val_mse: 0.0936\n",
      "Epoch 76/100\n",
      "2846/2846 [==============================] - 1s 189us/step - loss: 0.0858 - mse: 0.0858 - val_loss: 0.0873 - val_mse: 0.0873\n",
      "Epoch 77/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0823 - mse: 0.0823 - val_loss: 0.0859 - val_mse: 0.0859\n",
      "Epoch 78/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0925 - mse: 0.0925 - val_loss: 0.0967 - val_mse: 0.0967\n",
      "Epoch 79/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0887 - mse: 0.0887 - val_loss: 0.1114 - val_mse: 0.1114\n",
      "Epoch 80/100\n",
      "2846/2846 [==============================] - 1s 188us/step - loss: 0.0965 - mse: 0.0965 - val_loss: 0.1078 - val_mse: 0.1078\n",
      "Epoch 81/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.0868 - mse: 0.0868 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 82/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 83/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.0841 - mse: 0.0841 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 84/100\n",
      "2846/2846 [==============================] - 1s 198us/step - loss: 0.0830 - mse: 0.0830 - val_loss: 0.0959 - val_mse: 0.0959\n",
      "Epoch 85/100\n",
      "2846/2846 [==============================] - 1s 201us/step - loss: 0.0895 - mse: 0.0895 - val_loss: 0.1126 - val_mse: 0.1126\n",
      "Epoch 86/100\n",
      "2846/2846 [==============================] - 1s 205us/step - loss: 0.0847 - mse: 0.0847 - val_loss: 0.0933 - val_mse: 0.0933\n",
      "Epoch 87/100\n",
      "2846/2846 [==============================] - 1s 204us/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 88/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.1061 - val_mse: 0.1061\n",
      "Epoch 89/100\n",
      "2846/2846 [==============================] - 1s 194us/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 90/100\n",
      "2846/2846 [==============================] - 1s 192us/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 91/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.0854 - mse: 0.0854 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 92/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.1108 - mse: 0.1108 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 93/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0845 - val_mse: 0.0845\n",
      "Epoch 94/100\n",
      "2846/2846 [==============================] - 1s 197us/step - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 95/100\n",
      "2846/2846 [==============================] - 1s 199us/step - loss: 0.0832 - mse: 0.0832 - val_loss: 0.0871 - val_mse: 0.0871\n",
      "Epoch 96/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.0881 - val_mse: 0.0881\n",
      "Epoch 97/100\n",
      "2846/2846 [==============================] - 1s 196us/step - loss: 0.0898 - mse: 0.0898 - val_loss: 0.0889 - val_mse: 0.0889\n",
      "Epoch 98/100\n",
      "2846/2846 [==============================] - 1s 202us/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.1032 - val_mse: 0.1032\n",
      "Epoch 99/100\n",
      "2846/2846 [==============================] - 1s 195us/step - loss: 0.0847 - mse: 0.0847 - val_loss: 0.0887 - val_mse: 0.0887\n",
      "Epoch 100/100\n",
      "2846/2846 [==============================] - 1s 200us/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.1059 - val_mse: 0.1059\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform',  input_dim = 1))\n",
    "classifier.add(Dense(output_dim = 9, init = 'uniform'))\n",
    "classifier.add(Dense(1))\n",
    "classifier.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "history=classifier.fit(X_train, y_train,validation_data =[X_test,y_test], batch_size = 10, nb_epoch = 100)\n",
    "classifier.save('stock_prediction4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220/1220 [==============================] - 0s 25us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10588877648115158"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE,mse = classifier.evaluate(X_test,y_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index:  [1102 1103 1104 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [   0    1    2 ... 1099 1100 1101]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 74us/step - loss: 3971.4644 - mean_absolute_error: 3971.4614 - mse: 125904248.0000\n",
      "1102/1102 [==============================] - 0s 26us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [1102 1103 1104 ... 2201 2202 2203]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 52us/step - loss: 615.5781 - mean_absolute_error: 615.5779 - mse: 1138795.1250\n",
      "1102/1102 [==============================] - 0s 29us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [2204 2205 2206 ... 3303 3304 3305]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 51us/step - loss: 668.7360 - mean_absolute_error: 668.7359 - mse: 1542722.0000\n",
      "1102/1102 [==============================] - 0s 27us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [3306 3307 3308 ... 4405 4406 4407]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 51us/step - loss: 629.4912 - mean_absolute_error: 629.4910 - mse: 1526067.6250\n",
      "1102/1102 [==============================] - 0s 27us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [4408 4409 4410 ... 5507 5508 5509]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 50us/step - loss: 563.2805 - mean_absolute_error: 563.2805 - mse: 1522069.2500\n",
      "1102/1102 [==============================] - 0s 29us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625], [1261.5070437450374, 1261.507080078125, 1685222.0]]\n",
      "Train Index:  [   0    1    2 ... 7710 7711 7712] \n",
      "\n",
      "Test Index:  [5510 5511 5512 ... 6609 6610 6611]\n",
      "Epoch 1/1\n",
      "6611/6611 [==============================] - 0s 50us/step - loss: 380.6928 - mean_absolute_error: 380.6928 - mse: 650105.6875\n",
      "1102/1102 [==============================] - 0s 25us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625], [1261.5070437450374, 1261.507080078125, 1685222.0], [168.71415660601994, 168.7141571044922, 33889.8671875]]\n",
      "Train Index:  [   0    1    2 ... 6609 6610 6611] \n",
      "\n",
      "Test Index:  [6612 6613 6614 ... 7710 7711 7712]\n",
      "Epoch 1/1\n",
      "6612/6612 [==============================] - 0s 49us/step - loss: 218.7660 - mean_absolute_error: 218.7661 - mse: 207314.4531\n",
      "1101/1101 [==============================] - 0s 27us/step\n",
      "[[223.2855461106759, 223.2855682373047, 50045.81640625], [352.232067405853, 352.23211669921875, 153248.96875], [303.8979954935894, 303.8980407714844, 102263.3515625], [326.1897512113983, 326.18975830078125, 119041.1015625], [1261.5070437450374, 1261.507080078125, 1685222.0], [168.71415660601994, 168.7141571044922, 33889.8671875], [809.9979797973078, 809.998046875, 670389.9375]]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=7)\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "        model.fit(X_train, y_train)\n",
    "        return model.evaluate(X_test, y_test)\n",
    "\n",
    "scores_SVM=[]\n",
    "\n",
    "for train_index,test_index in kf.split(X,y):\n",
    "    print(\"Train Index: \", train_index, \"\\n\")\n",
    "    print(\"Test Index: \", test_index)\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    scores_SVM.append(get_score(classifier, X_train, X_test, y_train, y_test))\n",
    "    print(scores_SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
